{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pytorch로 시작하는 딥러닝"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 인공 신경망 (Aritificail Neural Network)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### AND, OR, NAND 게이트 구현"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "def And_gate(x1,x2):\r\n",
    "    w1 = 0.5\r\n",
    "    w2 = 0.5\r\n",
    "    b = -0.7\r\n",
    "    result = w1*x1 + w2*x2 + b\r\n",
    "    if result <= 0:\r\n",
    "        return 0\r\n",
    "    else:\r\n",
    "        return 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def NAND_gate(x1,x2):\r\n",
    "    w1 = -0.5\r\n",
    "    w2 = -0.5\r\n",
    "    b = 0.7\r\n",
    "    result = w1*x1 + w2*x2 + b\r\n",
    "    if result <= 0:\r\n",
    "        return 0\r\n",
    "    else :\r\n",
    "        return 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def OR_gate(x1,x2):\r\n",
    "    w1 = 0.6\r\n",
    "    w2 = 0.6\r\n",
    "    b = 0.5\r\n",
    "    result = w1*x1 + w2*x2 + b\r\n",
    "    if result <= 0:\r\n",
    "        return 0\r\n",
    "    else :\r\n",
    "        return 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 단층 퍼셉트론 구현하기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import torch\r\n",
    "\r\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
    "\r\n",
    "torch.manual_seed(777)\r\n",
    "if device == 'cuda' :\r\n",
    "    torch.cuda.manual_seed_all(777)\r\n",
    "\r\n",
    "X = torch.FloatTensor([[0,0], [0,1], [1,0], [1,1]]).to(device)\r\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)\r\n",
    "\r\n",
    "linear = torch.nn.Linear(2,1)\r\n",
    "sigmoid = torch.nn.Sigmoid()\r\n",
    "model = torch.nn.Sequential(linear, sigmoid).to(device)\r\n",
    "\r\n",
    "criterion = torch.nn.BCELoss().to(device)\r\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\r\n",
    "\r\n",
    "for epoch in range(10001):\r\n",
    "    optimizer.zero_grad()\r\n",
    "    hypothesis = model(X)\r\n",
    "\r\n",
    "    cost = criterion(hypothesis, Y)\r\n",
    "    cost.backward()\r\n",
    "    optimizer.step()\r\n",
    "\r\n",
    "    if epoch % 100 == 0:\r\n",
    "        print(epoch, cost.item())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 0.7273974418640137\n",
      "100 0.6951809525489807\n",
      "200 0.693813681602478\n",
      "300 0.6933774352073669\n",
      "400 0.6932310461997986\n",
      "500 0.6931794881820679\n",
      "600 0.6931601762771606\n",
      "700 0.6931526064872742\n",
      "800 0.6931495070457458\n",
      "900 0.6931481957435608\n",
      "1000 0.6931476593017578\n",
      "1100 0.6931474208831787\n",
      "1200 0.6931473016738892\n",
      "1300 0.6931473016738892\n",
      "1400 0.6931471824645996\n",
      "1500 0.6931471824645996\n",
      "1600 0.6931471824645996\n",
      "1700 0.6931471824645996\n",
      "1800 0.6931471824645996\n",
      "1900 0.6931471824645996\n",
      "2000 0.6931471824645996\n",
      "2100 0.6931471824645996\n",
      "2200 0.6931471824645996\n",
      "2300 0.6931471824645996\n",
      "2400 0.6931471824645996\n",
      "2500 0.6931471824645996\n",
      "2600 0.6931471824645996\n",
      "2700 0.6931471824645996\n",
      "2800 0.6931471824645996\n",
      "2900 0.6931471824645996\n",
      "3000 0.6931471824645996\n",
      "3100 0.6931471824645996\n",
      "3200 0.6931471228599548\n",
      "3300 0.6931471824645996\n",
      "3400 0.6931471824645996\n",
      "3500 0.6931471824645996\n",
      "3600 0.6931471824645996\n",
      "3700 0.6931471824645996\n",
      "3800 0.6931471824645996\n",
      "3900 0.6931471824645996\n",
      "4000 0.6931471824645996\n",
      "4100 0.6931471824645996\n",
      "4200 0.6931471824645996\n",
      "4300 0.6931471824645996\n",
      "4400 0.6931471824645996\n",
      "4500 0.6931471824645996\n",
      "4600 0.6931471824645996\n",
      "4700 0.6931471824645996\n",
      "4800 0.6931471824645996\n",
      "4900 0.6931471824645996\n",
      "5000 0.6931471824645996\n",
      "5100 0.6931471824645996\n",
      "5200 0.6931471824645996\n",
      "5300 0.6931471824645996\n",
      "5400 0.6931471824645996\n",
      "5500 0.6931471824645996\n",
      "5600 0.6931471824645996\n",
      "5700 0.6931471824645996\n",
      "5800 0.6931471824645996\n",
      "5900 0.6931471824645996\n",
      "6000 0.6931471824645996\n",
      "6100 0.6931471824645996\n",
      "6200 0.6931471824645996\n",
      "6300 0.6931471824645996\n",
      "6400 0.6931471824645996\n",
      "6500 0.6931471824645996\n",
      "6600 0.6931471824645996\n",
      "6700 0.6931471824645996\n",
      "6800 0.6931471824645996\n",
      "6900 0.6931471824645996\n",
      "7000 0.6931471824645996\n",
      "7100 0.6931471824645996\n",
      "7200 0.6931471824645996\n",
      "7300 0.6931471824645996\n",
      "7400 0.6931471824645996\n",
      "7500 0.6931471824645996\n",
      "7600 0.6931471824645996\n",
      "7700 0.6931471824645996\n",
      "7800 0.6931471824645996\n",
      "7900 0.6931471824645996\n",
      "8000 0.6931471824645996\n",
      "8100 0.6931471824645996\n",
      "8200 0.6931471824645996\n",
      "8300 0.6931471824645996\n",
      "8400 0.6931471824645996\n",
      "8500 0.6931471824645996\n",
      "8600 0.6931471824645996\n",
      "8700 0.6931471824645996\n",
      "8800 0.6931471824645996\n",
      "8900 0.6931471824645996\n",
      "9000 0.6931471824645996\n",
      "9100 0.6931471824645996\n",
      "9200 0.6931471824645996\n",
      "9300 0.6931471824645996\n",
      "9400 0.6931471824645996\n",
      "9500 0.6931471824645996\n",
      "9600 0.6931471824645996\n",
      "9700 0.6931471824645996\n",
      "9800 0.6931471824645996\n",
      "9900 0.6931471824645996\n",
      "10000 0.6931471824645996\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "with torch.no_grad():\r\n",
    "    hypothesis = model(X)\r\n",
    "    prediction = (hypothesis > 0.5).float()\r\n",
    "    accuracy = (prediction == Y).float().mean()\r\n",
    "    \r\n",
    "    print('모델의 출력값(Hypothesis): ', hypothesis.detach().cpu().numpy())\r\n",
    "    print('모델의 예측값(Predicted): ', prediction.detach().cpu().numpy())\r\n",
    "    print('실제값(Y): ', Y.cpu().numpy())\r\n",
    "    print('정확도(Accuracy): ', accuracy.item())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "모델의 출력값(Hypothesis):  [[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]]\n",
      "모델의 예측값(Predicted):  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "실제값(Y):  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "정확도(Accuracy):  0.5\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "다층 퍼셉트론 구현하기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "\r\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
    "\r\n",
    "torch.manual_seed(777)\r\n",
    "if device == 'cuda':\r\n",
    "    torch.cuda.manual_seed_all(777)\r\n",
    "\r\n",
    "X = torch.FloatTensor([[0,0], [0,1], [1,0], [1,1]]).to(device)\r\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)\r\n",
    "\r\n",
    "model = nn.Sequential(\r\n",
    "        nn.Linear(2,10,bias=True),\r\n",
    "        nn.Sigmoid(),\r\n",
    "        nn.Linear(10,10,bias=True),\r\n",
    "        nn.Sigmoid(),\r\n",
    "        nn.Linear(10,10,bias=True),\r\n",
    "        nn.Sigmoid(),\r\n",
    "        nn.Linear(10,1,bias=True),\r\n",
    "        nn.Sigmoid()\r\n",
    "        ).to(device)\r\n",
    "\r\n",
    "criterion = nn.BCELoss().to(device)\r\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1)\r\n",
    "\r\n",
    "for epoch in range(10001):\r\n",
    "    \r\n",
    "    optimizer.zero_grad()\r\n",
    "    hypothesis = model(X)\r\n",
    "\r\n",
    "    cost = criterion(hypothesis, Y)\r\n",
    "    cost.backward()\r\n",
    "    optimizer.step()\r\n",
    "\r\n",
    "    if epoch % 100 == 0:\r\n",
    "        print(epoch, cost.item())        \r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 0.6948983669281006\n",
      "100 0.6931558847427368\n",
      "200 0.6931535005569458\n",
      "300 0.6931513547897339\n",
      "400 0.6931493282318115\n",
      "500 0.6931473016738892\n",
      "600 0.6931453943252563\n",
      "700 0.6931434869766235\n",
      "800 0.6931416988372803\n",
      "900 0.6931397914886475\n",
      "1000 0.6931380033493042\n",
      "1100 0.6931362152099609\n",
      "1200 0.6931343078613281\n",
      "1300 0.6931324005126953\n",
      "1400 0.6931304931640625\n",
      "1500 0.6931284666061401\n",
      "1600 0.6931264400482178\n",
      "1700 0.6931242942810059\n",
      "1800 0.6931220293045044\n",
      "1900 0.6931196451187134\n",
      "2000 0.6931171417236328\n",
      "2100 0.6931145191192627\n",
      "2200 0.6931115984916687\n",
      "2300 0.6931085586547852\n",
      "2400 0.693105161190033\n",
      "2500 0.6931014657020569\n",
      "2600 0.6930974721908569\n",
      "2700 0.6930930018424988\n",
      "2800 0.6930880546569824\n",
      "2900 0.6930825710296631\n",
      "3000 0.6930763125419617\n",
      "3100 0.6930692791938782\n",
      "3200 0.6930612325668335\n",
      "3300 0.6930519342422485\n",
      "3400 0.693041205406189\n",
      "3500 0.693028450012207\n",
      "3600 0.6930133104324341\n",
      "3700 0.6929951906204224\n",
      "3800 0.6929729580879211\n",
      "3900 0.6929453015327454\n",
      "4000 0.6929103136062622\n",
      "4100 0.6928650140762329\n",
      "4200 0.6928046941757202\n",
      "4300 0.6927220225334167\n",
      "4400 0.692604124546051\n",
      "4500 0.6924278736114502\n",
      "4600 0.692147970199585\n",
      "4700 0.6916665434837341\n",
      "4800 0.6907395720481873\n",
      "4900 0.6886204481124878\n",
      "5000 0.6820821762084961\n",
      "5100 0.6472558379173279\n",
      "5200 0.4495784044265747\n",
      "5300 0.041401054710149765\n",
      "5400 0.00973653607070446\n",
      "5500 0.0050338273867964745\n",
      "5600 0.00329551356844604\n",
      "5700 0.0024154414422810078\n",
      "5800 0.0018910930957645178\n",
      "5900 0.0015457704430446029\n",
      "6000 0.0013024783693253994\n",
      "6100 0.001122395507991314\n",
      "6200 0.0009841559221968055\n",
      "6300 0.0008749148109927773\n",
      "6400 0.0007865495281293988\n",
      "6500 0.0007136262720450759\n",
      "6600 0.0006525927456095815\n",
      "6700 0.000600747880525887\n",
      "6800 0.0005561667494475842\n",
      "6900 0.0005174618563614786\n",
      "7000 0.0004836336011067033\n",
      "7100 0.0004537721397355199\n",
      "7200 0.0004272061923984438\n",
      "7300 0.00040348825859837234\n",
      "7400 0.00038214115193113685\n",
      "7500 0.00036286652903072536\n",
      "7600 0.00034532143035903573\n",
      "7700 0.00032935672788880765\n",
      "7800 0.000314718927256763\n",
      "7900 0.00030131853418424726\n",
      "8000 0.0002889616880565882\n",
      "8100 0.0002774993481580168\n",
      "8200 0.0002669314562808722\n",
      "8300 0.0002570493088569492\n",
      "8400 0.00024786783615127206\n",
      "8500 0.00023931238683871925\n",
      "8600 0.00023129362671170384\n",
      "8700 0.0002237667649751529\n",
      "8800 0.00021670199930667877\n",
      "8900 0.00021005462622269988\n",
      "9000 0.000203779898583889\n",
      "9100 0.0001978629152290523\n",
      "9200 0.00019222912669647485\n",
      "9300 0.00018693818128667772\n",
      "9400 0.00018191552953794599\n",
      "9500 0.00017716118600219488\n",
      "9600 0.00017261551693081856\n",
      "9700 0.00016829342348501086\n",
      "9800 0.00016415018762927502\n",
      "9900 0.00016021561168599874\n",
      "10000 0.0001565046259202063\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "with torch.no_grad():\r\n",
    "    hypothesis = model(X)\r\n",
    "    prediction = (hypothesis > 0.5).float()\r\n",
    "    accuracy = (prediction == Y).float().mean()\r\n",
    "\r\n",
    "    print('모델의 출력값(Hypothesis): ', hypothesis.detach().cpu().numpy())\r\n",
    "    print('모델의 예측값(Predicted): ', prediction.detach().cpu().numpy())\r\n",
    "    print('실제값(Y): ', Y.cpu().numpy())\r\n",
    "    print('정확도(Accuracy): ', accuracy.item())    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "모델의 출력값(Hypothesis):  [[1.1168354e-04]\n",
      " [9.9982882e-01]\n",
      " [9.9984241e-01]\n",
      " [1.8533420e-04]]\n",
      "모델의 예측값(Predicted):  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "실제값(Y):  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "정확도(Accuracy):  1.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 다층 퍼셉트론으로 손글씨 분류하기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "%matplotlib inline\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from sklearn.datasets import load_digits\r\n",
    "digits = load_digits()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "print(digits.images[0])\r\n",
    "print(digits.target[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n",
      "0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "print('전체 샘플의 수 : {}'.format(len(digits.images)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "전체 샘플의 수 : 1797\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "len(digits)으로 하면 안된다. 해당 데이터가 dictionary 형태로 이루어져있기 때문에 data의 길이가 아닌 dictionary의 길이가 나옴. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "images_and_labels = list(zip(digits.images, digits.target))\r\n",
    "for index, (image, label) in enumerate(images_and_labels[:5]):\r\n",
    "    plt.subplot(2,5,index+1)\r\n",
    "    plt.axis('off')\r\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\r\n",
    "    plt.title('sample: %i' % label)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "for i in range(5):\r\n",
    "    print(i, '번 인덱스 샘플의 레이블 : ', digits.target[i])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 번 인덱스 샘플의 레이블 :  0\n",
      "1 번 인덱스 샘플의 레이블 :  1\n",
      "2 번 인덱스 샘플의 레이블 :  2\n",
      "3 번 인덱스 샘플의 레이블 :  3\n",
      "4 번 인덱스 샘플의 레이블 :  4\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "print(digits.data[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
      " 15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
      "  0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
      "  0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "X = digits.data\r\n",
    "Y = digits.target"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torch import optim\r\n",
    "\r\n",
    "model = nn.Sequential(\r\n",
    "        nn.Linear(64, 32),\r\n",
    "        nn.ReLU(),\r\n",
    "        nn.Linear(32, 16),\r\n",
    "        nn.ReLU(),\r\n",
    "        nn.Linear(16, 10)\r\n",
    "        )\r\n",
    "\r\n",
    "X = torch.tensor(X, dtype = torch.float32)\r\n",
    "Y = torch.tensor(Y, dtype = torch.int64)\r\n",
    "\r\n",
    "loss_fn = nn.CrossEntropyLoss()\r\n",
    "optimizer = optim.Adam(model.parameters())\r\n",
    "\r\n",
    "losses = []\r\n",
    "\r\n",
    "for epoch in range(100):\r\n",
    "    \r\n",
    "    optimizer.zero_grad()\r\n",
    "    y_pred = model(X)\r\n",
    "\r\n",
    "    loss = loss_fn(y_pred, Y)\r\n",
    "    loss.backward()\r\n",
    "    optimizer.step()\r\n",
    "\r\n",
    "    if epoch % 10 == 0:\r\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(epoch, 100, loss.item()))\r\n",
    "\r\n",
    "    losses.append(loss.item())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch    0/100 Cost: 2.381846\n",
      "Epoch   10/100 Cost: 2.086940\n",
      "Epoch   20/100 Cost: 1.844468\n",
      "Epoch   30/100 Cost: 1.555474\n",
      "Epoch   40/100 Cost: 1.246410\n",
      "Epoch   50/100 Cost: 0.968091\n",
      "Epoch   60/100 Cost: 0.724376\n",
      "Epoch   70/100 Cost: 0.519714\n",
      "Epoch   80/100 Cost: 0.380598\n",
      "Epoch   90/100 Cost: 0.293385\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "plt.plot(losses)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14b09762df0>]"
      ]
     },
     "metadata": {},
     "execution_count": 31
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MNIST 분류하기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "%matplotlib inline\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import pandas as pd\r\n",
    "from sklearn.datasets import fetch_openml"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "mnist = fetch_openml('mnist_784', version=1, cache=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "mnist.data = np.array(mnist.data)\r\n",
    "mnist.target = np.array(mnist.target.astype(np.int8))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "mnist.data[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   3.,  18.,\n",
       "        18.,  18., 126., 136., 175.,  26., 166., 255., 247., 127.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        30.,  36.,  94., 154., 170., 253., 253., 253., 253., 253., 225.,\n",
       "       172., 253., 242., 195.,  64.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  49., 238., 253., 253., 253., 253.,\n",
       "       253., 253., 253., 253., 251.,  93.,  82.,  82.,  56.,  39.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        18., 219., 253., 253., 253., 253., 253., 198., 182., 247., 241.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,  80., 156., 107., 253.,\n",
       "       253., 205.,  11.,   0.,  43., 154.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,  14.,   1., 154., 253.,  90.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       139., 253., 190.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,  11., 190., 253.,  70.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,  35., 241., 225., 160., 108.,   1.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  81., 240.,\n",
       "       253., 253., 119.,  25.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  45., 186., 253., 253., 150.,  27.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,  16.,  93., 252., 253., 187.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 249., 253.,\n",
       "       249.,  64.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,  46., 130., 183., 253., 253., 207.,   2.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  39., 148., 229., 253., 253., 253.,\n",
       "       250., 182.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  24., 114.,\n",
       "       221., 253., 253., 253., 253., 201.,  78.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,  23.,  66., 213., 253., 253., 253., 253., 198.,  81.,\n",
       "         2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,  18., 171., 219., 253., 253.,\n",
       "       253., 253., 195.,  80.,   9.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  55.,\n",
       "       172., 226., 253., 253., 253., 253., 244., 133.,  11.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0., 136., 253., 253., 253., 212., 135.,\n",
       "       132.,  16.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.])"
      ]
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "X = mnist.data/255\r\n",
    "y = mnist.target"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "X[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "       0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117647, 0.36862745, 0.60392157,\n",
       "       0.66666667, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235294, 0.6745098 , 0.99215686, 0.94901961,\n",
       "       0.76470588, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215686, 0.93333333,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.98431373, 0.36470588,\n",
       "       0.32156863, 0.32156863, 0.21960784, 0.15294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.85882353, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.71372549,\n",
       "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31372549, 0.61176471, 0.41960784, 0.99215686, 0.99215686,\n",
       "       0.80392157, 0.04313725, 0.        , 0.16862745, 0.60392157,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "       0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54509804,\n",
       "       0.99215686, 0.74509804, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04313725, 0.74509804, 0.99215686,\n",
       "       0.2745098 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.1372549 , 0.94509804, 0.88235294, 0.62745098,\n",
       "       0.42352941, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31764706, 0.94117647, 0.99215686, 0.99215686, 0.46666667,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "       0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.36470588,\n",
       "       0.98823529, 0.99215686, 0.73333333, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.97647059, 0.99215686,\n",
       "       0.97647059, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.50980392,\n",
       "       0.71764706, 0.99215686, 0.99215686, 0.81176471, 0.00784314,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "       0.58039216, 0.89803922, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.98039216, 0.71372549, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.25882353, 0.83529412, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.31764706,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.67058824, 0.85882353,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.76470588,\n",
       "       0.31372549, 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568627, 0.6745098 ,\n",
       "       0.88627451, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.95686275, 0.52156863, 0.04313725, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53333333, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.83137255, 0.52941176, 0.51764706, 0.0627451 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "plt.imshow(X[0].reshape(28,28), cmap='gray')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b4113f5e80>"
      ]
     },
     "metadata": {},
     "execution_count": 104
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAN80lEQVR4nO3df6hcdXrH8c+ncf3DrBpTMYasNhuRWBWbLRqLSl2RrD9QNOqWDVgsBrN/GHChhEr6xyolEuqP0qAsuYu6sWyzLqgYZVkVo6ZFCF5j1JjU1YrdjV6SSozG+KtJnv5xT+Su3vnOzcyZOZP7vF9wmZnzzJnzcLife87Md879OiIEYPL7k6YbANAfhB1IgrADSRB2IAnCDiRxRD83ZpuP/oEeiwiPt7yrI7vtS22/aftt27d281oAesudjrPbniLpd5IWSNou6SVJiyJia2EdjuxAj/XiyD5f0tsR8U5EfCnpV5Ku6uL1APRQN2GfJekPYx5vr5b9EdtLbA/bHu5iWwC61M0HdOOdKnzjND0ihiQNSZzGA03q5si+XdJJYx5/R9L73bUDoFe6CftLkk61/V3bR0r6kaR19bQFoG4dn8ZHxD7bSyU9JWmKpAci4o3aOgNQq46H3jraGO/ZgZ7ryZdqABw+CDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUii4ymbcXiYMmVKsX7sscf2dPtLly5tWTvqqKOK686dO7dYv/nmm4v1u+66q2Vt0aJFxXU///zzYn3lypXF+u23316sN6GrsNt+V9IeSfsl7YuIs+toCkD96jiyXxQRH9TwOgB6iPfsQBLdhj0kPW37ZdtLxnuC7SW2h20Pd7ktAF3o9jT+/Ih43/YJkp6x/V8RsWHsEyJiSNKQJNmOLrcHoENdHdkj4v3qdqekxyTNr6MpAPXrOOy2p9o++uB9ST+QtKWuxgDUq5vT+BmSHrN98HX+PSJ+W0tXk8zJJ59crB955JHF+nnnnVesX3DBBS1r06ZNK6577bXXFutN2r59e7G+atWqYn3hwoUta3v27Cmu++qrrxbrL7zwQrE+iDoOe0S8I+kvauwFQA8x9AYkQdiBJAg7kARhB5Ig7EASjujfl9om6zfo5s2bV6yvX7++WO/1ZaaD6sCBA8X6jTfeWKx/8sknHW97ZGSkWP/www+L9TfffLPjbfdaRHi85RzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtlrMH369GJ948aNxfqcOXPqbKdW7XrfvXt3sX7RRRe1rH355ZfFdbN+/6BbjLMDyRF2IAnCDiRB2IEkCDuQBGEHkiDsQBJM2VyDXbt2FevLli0r1q+44opi/ZVXXinW2/1L5ZLNmzcX6wsWLCjW9+7dW6yfccYZLWu33HJLcV3UiyM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTB9ewD4JhjjinW200vvHr16pa1xYsXF9e9/vrri/W1a9cW6xg8HV/PbvsB2zttbxmzbLrtZ2y/Vd0eV2ezAOo3kdP4X0i69GvLbpX0bEScKunZ6jGAAdY27BGxQdLXvw96laQ11f01kq6uty0Adev0u/EzImJEkiJixPYJrZ5oe4mkJR1uB0BNen4hTEQMSRqS+IAOaFKnQ287bM+UpOp2Z30tAeiFTsO+TtIN1f0bJD1eTzsAeqXtabzttZK+L+l429sl/VTSSkm/tr1Y0u8l/bCXTU52H3/8cVfrf/TRRx2ve9NNNxXrDz/8cLHebo51DI62YY+IRS1KF9fcC4Ae4uuyQBKEHUiCsANJEHYgCcIOJMElrpPA1KlTW9aeeOKJ4roXXnhhsX7ZZZcV608//XSxjv5jymYgOcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9knulFNOKdY3bdpUrO/evbtYf+6554r14eHhlrX77ruvuG4/fzcnE8bZgeQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtmTW7hwYbH+4IMPFutHH310x9tevnx5sf7QQw8V6yMjIx1vezJjnB1IjrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcHUVnnnlmsX7PPfcU6xdf3Plkv6tXry7WV6xYUay/9957HW/7cNbxOLvtB2zvtL1lzLLbbL9ne3P1c3mdzQKo30RO438h6dJxlv9LRMyrfn5Tb1sA6tY27BGxQdKuPvQCoIe6+YBuqe3XqtP841o9yfYS28O2W/8zMgA912nYfybpFEnzJI1IurvVEyNiKCLOjoizO9wWgBp0FPaI2BER+yPigKSfS5pfb1sA6tZR2G3PHPNwoaQtrZ4LYDC0HWe3vVbS9yUdL2mHpJ9Wj+dJCknvSvpxRLS9uJhx9sln2rRpxfqVV17ZstbuWnl73OHir6xfv75YX7BgQbE+WbUaZz9iAisuGmfx/V13BKCv+LoskARhB5Ig7EAShB1IgrADSXCJKxrzxRdfFOtHHFEeLNq3b1+xfskll7SsPf/888V1D2f8K2kgOcIOJEHYgSQIO5AEYQeSIOxAEoQdSKLtVW/I7ayzzirWr7vuumL9nHPOaVlrN47eztatW4v1DRs2dPX6kw1HdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2SW7u3LnF+tKlS4v1a665plg/8cQTD7mnidq/f3+xPjJS/u/lBw4cqLOdwx5HdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2w0C7sexFi8abaHdUu3H02bNnd9JSLYaHh4v1FStWFOvr1q2rs51Jr+2R3fZJtp+zvc32G7ZvqZZPt/2M7beq2+N63y6ATk3kNH6fpL+PiD+X9FeSbrZ9uqRbJT0bEadKerZ6DGBAtQ17RIxExKbq/h5J2yTNknSVpDXV09ZIurpHPQKowSG9Z7c9W9L3JG2UNCMiRqTRPwi2T2ixzhJJS7rsE0CXJhx229+W9Iikn0TEx/a4c8d9Q0QMSRqqXoOJHYGGTGjozfa3NBr0X0bEo9XiHbZnVvWZknb2pkUAdWh7ZPfoIfx+Sdsi4p4xpXWSbpC0srp9vCcdTgIzZswo1k8//fRi/d577y3WTzvttEPuqS4bN24s1u+8886WtccfL//KcIlqvSZyGn++pL+V9LrtzdWy5RoN+a9tL5b0e0k/7EmHAGrRNuwR8Z+SWr1Bv7jedgD0Cl+XBZIg7EAShB1IgrADSRB2IAkucZ2g6dOnt6ytXr26uO68efOK9Tlz5nTSUi1efPHFYv3uu+8u1p966qli/bPPPjvkntAbHNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IIk04+znnntusb5s2bJiff78+S1rs2bN6qinunz66acta6tWrSque8cddxTre/fu7agnDB6O7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQRJpx9oULF3ZV78bWrVuL9SeffLJY37dvX7FeuuZ89+7dxXWRB0d2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUjCEVF+gn2SpIcknSjpgKShiPhX27dJuknS/1ZPXR4Rv2nzWuWNAehaRIw76/JEwj5T0syI2GT7aEkvS7pa0t9I+iQi7ppoE4Qd6L1WYZ/I/Owjkkaq+3tsb5PU7L9mAXDIDuk9u+3Zkr4naWO1aKnt12w/YPu4FusssT1se7i7VgF0o+1p/FdPtL8t6QVJKyLiUdszJH0gKST9k0ZP9W9s8xqcxgM91vF7dkmy/S1JT0p6KiLuGac+W9KTEXFmm9ch7ECPtQp729N425Z0v6RtY4NefXB30EJJW7ptEkDvTOTT+Ask/Yek1zU69CZJyyUtkjRPo6fx70r6cfVhXum1OLIDPdbVaXxdCDvQex2fxgOYHAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ9HvK5g8k/c+Yx8dXywbRoPY2qH1J9NapOnv7s1aFvl7P/o2N28MRcXZjDRQMam+D2pdEb53qV2+cxgNJEHYgiabDPtTw9ksGtbdB7Uuit071pbdG37MD6J+mj+wA+oSwA0k0Enbbl9p+0/bbtm9toodWbL9r+3Xbm5uen66aQ2+n7S1jlk23/Yztt6rbcefYa6i322y/V+27zbYvb6i3k2w/Z3ub7Tds31Itb3TfFfrqy37r+3t221Mk/U7SAknbJb0kaVFEbO1rIy3YflfS2RHR+BcwbP+1pE8kPXRwai3b/yxpV0SsrP5QHhcR/zAgvd2mQ5zGu0e9tZpm/O/U4L6rc/rzTjRxZJ8v6e2IeCcivpT0K0lXNdDHwIuIDZJ2fW3xVZLWVPfXaPSXpe9a9DYQImIkIjZV9/dIOjjNeKP7rtBXXzQR9lmS/jDm8XYN1nzvIelp2y/bXtJ0M+OYcXCarer2hIb7+bq203j309emGR+YfdfJ9OfdaiLs401NM0jjf+dHxF9KukzSzdXpKibmZ5JO0egcgCOS7m6ymWqa8Uck/SQiPm6yl7HG6asv+62JsG+XdNKYx9+R9H4DfYwrIt6vbndKekyjbzsGyY6DM+hWtzsb7ucrEbEjIvZHxAFJP1eD+66aZvwRSb+MiEerxY3vu/H66td+ayLsL0k61fZ3bR8p6UeS1jXQxzfYnlp9cCLbUyX9QIM3FfU6STdU92+Q9HiDvfyRQZnGu9U042p43zU+/XlE9P1H0uUa/UT+vyX9YxM9tOhrjqRXq583mu5N0lqNntb9n0bPiBZL+lNJz0p6q7qdPkC9/ZtGp/Z+TaPBmtlQbxdo9K3ha5I2Vz+XN73vCn31Zb/xdVkgCb5BByRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ/D+f1mbt6t55/AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "import torch\r\n",
    "from torch.utils.data import TensorDataset, DataLoader\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/7, random_state=0)\r\n",
    "\r\n",
    "X_train = torch.Tensor(X_train)\r\n",
    "X_test = torch.Tensor(X_test)\r\n",
    "y_train = torch.Tensor(y_train)\r\n",
    "y_test = torch.Tensor(y_test)\r\n",
    "\r\n",
    "dataset_train = TensorDataset(X_train, y_train)\r\n",
    "dataset_test = TensorDataset(X_test, y_test)\r\n",
    "\r\n",
    "loader_train = DataLoader(dataset_train, batch_size=64, shuffle=True)\r\n",
    "loader_test = DataLoader(dataset_test, batch_size=64, shuffle=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "import torch.nn as nn\r\n",
    "\r\n",
    "model = nn.Sequential()\r\n",
    "model.add_module('fc1', nn.Linear(784,100))\r\n",
    "model.add_module('relu1', nn.ReLU())\r\n",
    "model.add_module('fc2', nn.Linear(100,100))\r\n",
    "model.add_module('relu2', nn.ReLU())\r\n",
    "model.add_module('fc3', nn.Linear(100,10))\r\n",
    "\r\n",
    "print(model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sequential(\n",
      "  (fc1): Linear(in_features=784, out_features=100, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "import torch.optim as optim\r\n",
    "\r\n",
    "loss_fn = nn.CrossEntropyLoss()\r\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "source": [
    "def train(epoch):\r\n",
    "    \r\n",
    "    model.train()\r\n",
    "\r\n",
    "    for data, target in loader_train:\r\n",
    "        target = torch.tensor(target, dtype=torch.long)\r\n",
    "        optimizer.zero_grad()\r\n",
    "        outputs = model(data)\r\n",
    "        loss = loss_fn(outputs, target)\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "    print(\"epoch{}：완료\".format(epoch))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "def test():\r\n",
    "    \r\n",
    "    model.eval()\r\n",
    "    correct = 0\r\n",
    "\r\n",
    "    with torch.no_grad():\r\n",
    "        for data, target in loader_test:\r\n",
    "            outputs = model(data)\r\n",
    "            _, predicted = torch.max(outputs.data, 1)\r\n",
    "            correct += predicted.eq(target.data.view_as(predicted)).sum()\r\n",
    "\r\n",
    "    data_num = len(loader_test.dataset)\r\n",
    "    print('\\n테스트 데이터에서 예측 정확도: {}/{} ({:.0f}%)\\n'.format(correct,\r\n",
    "                                                   data_num, 100. * correct / data_num))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "test()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "테스트 데이터에서 예측 정확도: 1324/10000 (13%)\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "source": [
    "for epoch in range(3):\r\n",
    "    train(epoch)\r\n",
    "\r\n",
    "test()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\DMQA\\AppData\\Local\\Temp/ipykernel_11528/2902682684.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target, dtype=torch.long)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch0：완료\n",
      "epoch1：완료\n",
      "epoch2：완료\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 9583/10000 (96%)\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "source": [
    "index = 2018\r\n",
    "\r\n",
    "model.eval()\r\n",
    "data = X_test[index]\r\n",
    "output = model(data)\r\n",
    "_, predicted = torch.max(output.data, 0)\r\n",
    "\r\n",
    "print('예측 결과 : {}'.format(predicted))\r\n",
    "\r\n",
    "X_test_show = (X_test[index]).numpy()\r\n",
    "plt.imshow(X_test_show.reshape(28,28), cmap='gray')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "예측 결과 : 2\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b41103ce50>"
      ]
     },
     "metadata": {},
     "execution_count": 146
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "책의 일부분이 안맞아서 오류 수정에 약간 걸림돌이 있었음  \r\n",
    "\r\n",
    "아래는 총 종합 버전 :)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib inline\r\n",
    "\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "from torch.utils.data import TensorDataset, DataLoader\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from sklearn.datasets import fetch_openml\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True)\r\n",
    "\r\n",
    "mnist.data = np.array(mnist.data)\r\n",
    "mnist.target = np.array(mnist.target.astype(np.int8))\r\n",
    "\r\n",
    "X = mnist.data/255\r\n",
    "y = mnist.target\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/7, random_state=0)\r\n",
    "\r\n",
    "X_train = torch.Tensor(X_train)\r\n",
    "X_test = torch.Tensor(X_test)\r\n",
    "y_train = torch.Tensor(y_train)\r\n",
    "y_test = torch.Tensor(y_test)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('main': conda)"
  },
  "interpreter": {
   "hash": "5777bc8a7577125a1c00ed1671130ea029cae56addc813f4c39a4f837e26f28b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}