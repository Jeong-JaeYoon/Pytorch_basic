{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# batch normalization이 미치는 영향"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#np.set_printoptions(threshold=np.inf, linewidth=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DMQA\\anaconda3\\envs\\main\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "mnist_train = datasets.MNIST(root='MNIST_data/', train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_test = datasets.MNIST(root='MNIST_data/', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(dataset=mnist_train, batch_size=32, shuffle=False, drop_last=True)\n",
    "train_test = DataLoader(dataset=mnist_test, batch_size=32, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1 = nn.Linear(784,32,bias=True)\n",
    "linear2 = nn.Linear(32,32,bias=True)\n",
    "linear3 = nn.Linear(32,32,bias=True)\n",
    "\n",
    "class basic_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(basic_model, self).__init__()\n",
    "        self.fc1 = linear1\n",
    "        self.fc2 = linear2\n",
    "        self.fc3 = linear3\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        print(out)\n",
    "        out = self.relu(out)\n",
    "        print(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "class batchnorm_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(batchnorm_model,self).__init__()\n",
    "        self.fc1 = linear1\n",
    "        self.fc2 = linear2 \n",
    "        self.fc3 = linear3\n",
    "        self.relu = nn.ReLU()\n",
    "        self.batch1 = nn.BatchNorm1d(32)\n",
    "        self.batch2 = nn.BatchNorm1d(32)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        print(out)\n",
    "        out = self.batch1(out)\n",
    "        print(out)\n",
    "        out = self.relu(out)\n",
    "        print(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.batch2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1250,  0.2667, -0.0691,  ...,  0.0338,  0.1995, -0.7375],\n",
      "        [ 0.0489,  0.1386, -0.2254,  ...,  0.0702,  0.1072, -0.5416],\n",
      "        [-0.2138, -0.1810, -0.1133,  ...,  0.0398,  0.1150, -0.2616],\n",
      "        ...,\n",
      "        [-0.1116, -0.0278,  0.0118,  ...,  0.0312,  0.0364, -0.1396],\n",
      "        [-0.1603, -0.0657,  0.2640,  ...,  0.2576, -0.0282, -0.2971],\n",
      "        [ 0.2063,  0.2765, -0.0191,  ..., -0.2898, -0.0010, -0.6564]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0000, 0.2667, 0.0000,  ..., 0.0338, 0.1995, 0.0000],\n",
      "        [0.0489, 0.1386, 0.0000,  ..., 0.0702, 0.1072, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0398, 0.1150, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0118,  ..., 0.0312, 0.0364, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2640,  ..., 0.2576, 0.0000, 0.0000],\n",
      "        [0.2063, 0.2765, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "base_model = basic_model()\n",
    "\n",
    "for epoch in range(1):\n",
    "    for X,Y in train_loader:\n",
    "        X = X.view(-1, 28*28)\n",
    "        Y = Y\n",
    "\n",
    "        base_predict = base_model(X)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1250,  0.2667, -0.0691,  ...,  0.0338,  0.1995, -0.7375],\n",
      "        [ 0.0489,  0.1386, -0.2254,  ...,  0.0702,  0.1072, -0.5416],\n",
      "        [-0.2138, -0.1810, -0.1133,  ...,  0.0398,  0.1150, -0.2616],\n",
      "        ...,\n",
      "        [-0.1116, -0.0278,  0.0118,  ...,  0.0312,  0.0364, -0.1396],\n",
      "        [-0.1603, -0.0657,  0.2640,  ...,  0.2576, -0.0282, -0.2971],\n",
      "        [ 0.2063,  0.2765, -0.0191,  ..., -0.2898, -0.0010, -0.6564]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.3849,  1.2483, -0.3701,  ...,  0.3018,  0.7658, -1.8464],\n",
      "        [ 0.8460,  0.4542, -1.5535,  ...,  0.5685,  0.2573, -0.9579],\n",
      "        [-1.0134, -1.5276, -0.7049,  ...,  0.3455,  0.3003,  0.3122],\n",
      "        ...,\n",
      "        [-0.2901, -0.5780,  0.2422,  ...,  0.2827, -0.1326,  0.8654],\n",
      "        [-0.6352, -0.8131,  2.1516,  ...,  1.9398, -0.4883,  0.1510],\n",
      "        [ 1.9593,  1.3094,  0.0080,  ..., -2.0672, -0.3385, -1.4782]],\n",
      "       grad_fn=<NativeBatchNormBackward>)\n",
      "tensor([[0.0000, 1.2483, 0.0000,  ..., 0.3018, 0.7658, 0.0000],\n",
      "        [0.8460, 0.4542, 0.0000,  ..., 0.5685, 0.2573, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.3455, 0.3003, 0.3122],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.2422,  ..., 0.2827, 0.0000, 0.8654],\n",
      "        [0.0000, 0.0000, 2.1516,  ..., 1.9398, 0.0000, 0.1510],\n",
      "        [1.9593, 1.3094, 0.0080,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "bn_model = batchnorm_model()\n",
    "\n",
    "for epoch in range(1):\n",
    "    for X,Y in train_loader:\n",
    "        X = X.view(-1, 28*28)\n",
    "        Y = Y\n",
    "\n",
    "        bn_model_predict = bn_model(X)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0670, -0.0555, -0.1320,  ..., -0.2561,  0.4735,  0.2064],\n",
      "        [ 0.1682, -0.0104, -0.3163,  ...,  0.0014,  0.3961, -0.0819],\n",
      "        [-0.0427, -0.0915, -0.0578,  ..., -0.1353,  0.2736, -0.0332],\n",
      "        ...,\n",
      "        [-0.1127,  0.1074, -0.0797,  ..., -0.0825,  0.2056,  0.1114],\n",
      "        [-0.1161,  0.2110,  0.1304,  ..., -0.1562,  0.2155,  0.3483],\n",
      "        [-0.2512,  0.1737, -0.3614,  ...,  0.1445,  0.3043, -0.0791]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.4735, 0.2064],\n",
      "        [0.1682, 0.0000, 0.0000,  ..., 0.0014, 0.3961, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2736, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.1074, 0.0000,  ..., 0.0000, 0.2056, 0.1114],\n",
      "        [0.0000, 0.2110, 0.1304,  ..., 0.0000, 0.2155, 0.3483],\n",
      "        [0.0000, 0.1737, 0.0000,  ..., 0.1445, 0.3043, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "base_model = basic_model()\n",
    "base_criterion = torch.nn.CrossEntropyLoss()\n",
    "base_optimizer = optim.Adam(base_model.parameters(), lr=0.001)\n",
    "\n",
    "base_train_loss = []\n",
    "base_test_loss = []\n",
    "\n",
    "for epoch in range(1):\n",
    "    base_model.train()\n",
    "\n",
    "    for X,Y in train_loader:\n",
    "        X = X.view(-1, 28*28)\n",
    "        Y = Y\n",
    "\n",
    "        base_optimizer.zero_grad()\n",
    "        base_predict = base_model(X)\n",
    "        base_loss = base_criterion(base_predict, Y)\n",
    "        base_loss.backward()\n",
    "        base_optimizer.step()\n",
    "\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0258, -0.0024, -0.0681,  ..., -0.2877,  0.5658,  0.1672],\n",
      "        [ 0.2727,  0.0253, -0.2491,  ..., -0.0699,  0.4737, -0.1070],\n",
      "        [-0.0257, -0.0828, -0.0187,  ..., -0.1203,  0.3425, -0.0672],\n",
      "        ...,\n",
      "        [-0.0843,  0.1021, -0.0649,  ..., -0.0545,  0.2261,  0.1158],\n",
      "        [-0.1132,  0.2421,  0.2139,  ..., -0.1632,  0.3028,  0.3021],\n",
      "        [-0.1887,  0.2410, -0.3315,  ...,  0.1818,  0.3925, -0.1138]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.9752e-01, -6.9148e-01, -3.0383e-01,  ..., -1.2627e+00,\n",
      "          6.3101e-01,  7.4280e-01],\n",
      "        [ 2.9744e+00, -5.0733e-01, -1.8019e+00,  ...,  1.6190e-01,\n",
      "          1.8298e-01, -1.4799e+00],\n",
      "        [ 1.9850e-01, -1.2254e+00,  1.0448e-01,  ..., -1.6815e-01,\n",
      "         -4.5468e-01, -1.1567e+00],\n",
      "        ...,\n",
      "        [-3.4700e-01,  2.9168e-03, -2.7751e-01,  ...,  2.6234e-01,\n",
      "         -1.0206e+00,  3.2635e-01],\n",
      "        [-6.1523e-01,  9.3232e-01,  2.0291e+00,  ..., -4.4855e-01,\n",
      "         -6.4783e-01,  1.8364e+00],\n",
      "        [-1.3184e+00,  9.2524e-01, -2.4835e+00,  ...,  1.8074e+00,\n",
      "         -2.1160e-01, -1.5349e+00]], grad_fn=<NativeBatchNormBackward>)\n",
      "tensor([[1.9752e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 6.3101e-01,\n",
      "         7.4280e-01],\n",
      "        [2.9744e+00, 0.0000e+00, 0.0000e+00,  ..., 1.6190e-01, 1.8298e-01,\n",
      "         0.0000e+00],\n",
      "        [1.9850e-01, 0.0000e+00, 1.0448e-01,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [0.0000e+00, 2.9168e-03, 0.0000e+00,  ..., 2.6234e-01, 0.0000e+00,\n",
      "         3.2635e-01],\n",
      "        [0.0000e+00, 9.3232e-01, 2.0291e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         1.8364e+00],\n",
      "        [0.0000e+00, 9.2524e-01, 0.0000e+00,  ..., 1.8074e+00, 0.0000e+00,\n",
      "         0.0000e+00]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bn_model = batchnorm_model()\n",
    "bn_criterion = torch.nn.CrossEntropyLoss()\n",
    "bn_optimizer = optim.Adam(bn_model.parameters(), lr=0.001)\n",
    "\n",
    "bn_train_loss = []\n",
    "bn_test_loss = []\n",
    "\n",
    "for epoch in range(1):\n",
    "    bn_model.train()\n",
    "\n",
    "    for X,Y in train_loader:\n",
    "        X = X.view(-1, 28*28)\n",
    "        Y = Y\n",
    "\n",
    "        bn_optimizer.zero_grad()\n",
    "        bn_predict = bn_model(X)\n",
    "        bn_loss = bn_criterion(bn_predict, Y)\n",
    "        bn_loss.backward()\n",
    "        bn_optimizer.step()\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_model = batchnorm_model()\n",
    "bn_criterion = torch.nn.CrossEntropyLoss()\n",
    "bn_optimizer = optim.Adam(bn_model.parameters(), lr=0.001)\n",
    "\n",
    "bn_train_loss = []\n",
    "bn_test_loss = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight\n",
      "tensor([[ 0.0184, -0.0158, -0.0069,  ...,  0.0068, -0.0041,  0.0025],\n",
      "        [-0.0274, -0.0224, -0.0309,  ..., -0.0029,  0.0013, -0.0167],\n",
      "        [ 0.0282, -0.0095, -0.0340,  ..., -0.0141,  0.0056, -0.0335],\n",
      "        ...,\n",
      "        [ 0.0226,  0.0331,  0.0182,  ...,  0.0150,  0.0278, -0.0073],\n",
      "        [-0.0210,  0.0144,  0.0214,  ..., -0.0308, -0.0335,  0.0085],\n",
      "        [ 0.0219,  0.0195, -0.0009,  ...,  0.0191,  0.0218, -0.0320]])\n",
      "fc1.bias\n",
      "tensor([-0.0307, -0.0331, -0.0263, -0.0178, -0.0344,  0.0138,  0.0016, -0.0208,\n",
      "         0.0306, -0.0286,  0.0310,  0.0326,  0.0169,  0.0296,  0.0092, -0.0179,\n",
      "         0.0081,  0.0100, -0.0235, -0.0033,  0.0248,  0.0040, -0.0298,  0.0020,\n",
      "        -0.0164, -0.0129, -0.0136, -0.0267, -0.0161,  0.0283,  0.0218,  0.0234])\n",
      "fc2.weight\n",
      "tensor([[-0.1084, -0.1104,  0.1025,  ...,  0.0448,  0.0729,  0.1699],\n",
      "        [-0.0593, -0.1072,  0.1283,  ..., -0.0471,  0.0327, -0.1190],\n",
      "        [-0.1477, -0.1216,  0.0104,  ...,  0.0205,  0.0137, -0.1070],\n",
      "        ...,\n",
      "        [-0.1121,  0.0123, -0.0682,  ..., -0.1026,  0.1203, -0.0791],\n",
      "        [-0.0191,  0.0246,  0.1755,  ..., -0.1550,  0.1343,  0.0649],\n",
      "        [ 0.0704,  0.1165,  0.0312,  ...,  0.1136,  0.1464, -0.0589]])\n",
      "fc2.bias\n",
      "tensor([ 0.0897,  0.0466, -0.1518, -0.0940, -0.0059,  0.1192,  0.0572, -0.0690,\n",
      "         0.0179,  0.1341, -0.0583, -0.1109, -0.0572,  0.1346,  0.0417,  0.0604,\n",
      "         0.0227,  0.1450,  0.1087,  0.0556,  0.0776,  0.0050,  0.1256, -0.0187,\n",
      "         0.1405,  0.0324,  0.1331,  0.0555, -0.0319,  0.0147, -0.1120, -0.1174])\n",
      "fc3.weight\n",
      "tensor([[-0.1492,  0.1563, -0.1242,  ...,  0.1630,  0.1054,  0.0210],\n",
      "        [ 0.1698, -0.1469, -0.0027,  ..., -0.1129, -0.1386,  0.1146],\n",
      "        [ 0.1621,  0.1153, -0.1494,  ..., -0.1035, -0.1642,  0.0960],\n",
      "        ...,\n",
      "        [ 0.0311,  0.0265,  0.1533,  ..., -0.0751, -0.0072,  0.0032],\n",
      "        [ 0.1186,  0.0438,  0.1389,  ..., -0.1700, -0.0386,  0.1093],\n",
      "        [-0.0979,  0.0015,  0.0385,  ...,  0.0289,  0.1272,  0.1079]])\n",
      "fc3.bias\n",
      "tensor([ 0.0621, -0.0485, -0.0582, -0.0848, -0.1148, -0.0081, -0.0594,  0.1474,\n",
      "        -0.1254, -0.1439,  0.1550, -0.0987,  0.1030,  0.0665, -0.0222,  0.1360,\n",
      "         0.0052, -0.0843,  0.0291,  0.0791,  0.1051, -0.0080,  0.0788,  0.1028,\n",
      "        -0.0258, -0.0891, -0.1780,  0.1291, -0.0454,  0.0049,  0.0629,  0.0189])\n",
      "fc1.weight\n",
      "tensor([[ 0.0184, -0.0158, -0.0069,  ...,  0.0068, -0.0041,  0.0025],\n",
      "        [-0.0274, -0.0224, -0.0309,  ..., -0.0029,  0.0013, -0.0167],\n",
      "        [ 0.0282, -0.0095, -0.0340,  ..., -0.0141,  0.0056, -0.0335],\n",
      "        ...,\n",
      "        [ 0.0226,  0.0331,  0.0182,  ...,  0.0150,  0.0278, -0.0073],\n",
      "        [-0.0210,  0.0144,  0.0214,  ..., -0.0308, -0.0335,  0.0085],\n",
      "        [ 0.0219,  0.0195, -0.0009,  ...,  0.0191,  0.0218, -0.0320]])\n",
      "fc1.bias\n",
      "tensor([-0.0307, -0.0331, -0.0263, -0.0178, -0.0344,  0.0138,  0.0016, -0.0208,\n",
      "         0.0306, -0.0286,  0.0310,  0.0326,  0.0169,  0.0296,  0.0092, -0.0179,\n",
      "         0.0081,  0.0100, -0.0235, -0.0033,  0.0248,  0.0040, -0.0298,  0.0020,\n",
      "        -0.0164, -0.0129, -0.0136, -0.0267, -0.0161,  0.0283,  0.0218,  0.0234])\n",
      "fc2.weight\n",
      "tensor([[-0.1084, -0.1104,  0.1025,  ...,  0.0448,  0.0729,  0.1699],\n",
      "        [-0.0593, -0.1072,  0.1283,  ..., -0.0471,  0.0327, -0.1190],\n",
      "        [-0.1477, -0.1216,  0.0104,  ...,  0.0205,  0.0137, -0.1070],\n",
      "        ...,\n",
      "        [-0.1121,  0.0123, -0.0682,  ..., -0.1026,  0.1203, -0.0791],\n",
      "        [-0.0191,  0.0246,  0.1755,  ..., -0.1550,  0.1343,  0.0649],\n",
      "        [ 0.0704,  0.1165,  0.0312,  ...,  0.1136,  0.1464, -0.0589]])\n",
      "fc2.bias\n",
      "tensor([ 0.0897,  0.0466, -0.1518, -0.0940, -0.0059,  0.1192,  0.0572, -0.0690,\n",
      "         0.0179,  0.1341, -0.0583, -0.1109, -0.0572,  0.1346,  0.0417,  0.0604,\n",
      "         0.0227,  0.1450,  0.1087,  0.0556,  0.0776,  0.0050,  0.1256, -0.0187,\n",
      "         0.1405,  0.0324,  0.1331,  0.0555, -0.0319,  0.0147, -0.1120, -0.1174])\n",
      "fc3.weight\n",
      "tensor([[-0.1492,  0.1563, -0.1242,  ...,  0.1630,  0.1054,  0.0210],\n",
      "        [ 0.1698, -0.1469, -0.0027,  ..., -0.1129, -0.1386,  0.1146],\n",
      "        [ 0.1621,  0.1153, -0.1494,  ..., -0.1035, -0.1642,  0.0960],\n",
      "        ...,\n",
      "        [ 0.0311,  0.0265,  0.1533,  ..., -0.0751, -0.0072,  0.0032],\n",
      "        [ 0.1186,  0.0438,  0.1389,  ..., -0.1700, -0.0386,  0.1093],\n",
      "        [-0.0979,  0.0015,  0.0385,  ...,  0.0289,  0.1272,  0.1079]])\n",
      "fc3.bias\n",
      "tensor([ 0.0621, -0.0485, -0.0582, -0.0848, -0.1148, -0.0081, -0.0594,  0.1474,\n",
      "        -0.1254, -0.1439,  0.1550, -0.0987,  0.1030,  0.0665, -0.0222,  0.1360,\n",
      "         0.0052, -0.0843,  0.0291,  0.0791,  0.1051, -0.0080,  0.0788,  0.1028,\n",
      "        -0.0258, -0.0891, -0.1780,  0.1291, -0.0454,  0.0049,  0.0629,  0.0189])\n",
      "batch1.weight\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "batch1.bias\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "batch1.running_mean\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "batch1.running_var\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "batch1.num_batches_tracked\n",
      "tensor(0)\n",
      "batch2.weight\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "batch2.bias\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "batch2.running_mean\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "batch2.running_var\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "batch2.num_batches_tracked\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "for names in base_model.state_dict():\n",
    "    print(names)\n",
    "    print(base_model.state_dict()[names])\n",
    "\n",
    "for name in bn_model.state_dict():\n",
    "    print(name)\n",
    "    print(bn_model.state_dict()[name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train loss vs Test loss 비교하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1875"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 cost:  6.162463978398591e-05\n",
      "epoch:  1 cost:  3.775424920604564e-05\n",
      "epoch:  2 cost:  1.9667701053549536e-05\n",
      "epoch:  3 cost:  1.3259685147204436e-05\n",
      "epoch:  4 cost:  1.0538067726884037e-05\n",
      "epoch:  5 cost:  8.068742317846045e-06\n",
      "epoch:  6 cost:  6.615039183088811e-06\n",
      "epoch:  7 cost:  6.827609922765987e-06\n",
      "epoch:  8 cost:  6.708504315611208e-06\n",
      "epoch:  9 cost:  5.4978104344627354e-06\n",
      "epoch:  10 cost:  6.794320142944343e-06\n",
      "epoch:  11 cost:  5.0577095862536225e-06\n",
      "epoch:  12 cost:  6.226142886589514e-06\n",
      "epoch:  13 cost:  1.1537786122062244e-05\n",
      "epoch:  14 cost:  6.850424597359961e-06\n"
     ]
    }
   ],
   "source": [
    "base_model = basic_model()\n",
    "base_criterion = torch.nn.CrossEntropyLoss()\n",
    "base_optimizer = optim.Adam(base_model.parameters(), lr=0.001)\n",
    "\n",
    "base_train_loss = []\n",
    "base_test_loss = []\n",
    "\n",
    "for epoch in range(15):\n",
    "    base_model.train()\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X,Y in train_loader:\n",
    "        X = X.view(-1, 28*28)\n",
    "        Y = Y\n",
    "\n",
    "        base_optimizer.zero_grad()\n",
    "        base_predict = base_model(X)\n",
    "        base_loss = base_criterion(base_predict, Y)\n",
    "        base_loss.backward()\n",
    "        base_optimizer.step()\n",
    "\n",
    "    avg_cost += base_loss / len(train_loader)\n",
    "    base_train_loss.append(avg_cost.item())\n",
    "\n",
    "    print('epoch: ', epoch, 'cost: ', avg_cost.item() )\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.162463978398591e-05,\n",
       " 3.775424920604564e-05,\n",
       " 1.9667701053549536e-05,\n",
       " 1.3259685147204436e-05,\n",
       " 1.0538067726884037e-05,\n",
       " 8.068742317846045e-06,\n",
       " 6.615039183088811e-06,\n",
       " 6.827609922765987e-06,\n",
       " 6.708504315611208e-06,\n",
       " 5.4978104344627354e-06,\n",
       " 6.794320142944343e-06,\n",
       " 5.0577095862536225e-06,\n",
       " 6.226142886589514e-06,\n",
       " 1.1537786122062244e-05,\n",
       " 6.850424597359961e-06]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(range(15),base_train_loss)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5777bc8a7577125a1c00ed1671130ea029cae56addc813f4c39a4f837e26f28b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('main': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
