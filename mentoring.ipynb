{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# batch normalization이 미치는 영향"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "#np.set_printoptions(threshold=np.inf, linewidth=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DMQA\\anaconda3\\envs\\main\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "mnist_train = datasets.MNIST(root='MNIST_data/', train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_test = datasets.MNIST(root='MNIST_data/', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(dataset=mnist_train, batch_size=32, shuffle=False, drop_last=True)\n",
    "train_test = DataLoader(dataset=mnist_test, batch_size=32, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1 = nn.Linear(784,32,bias=True)\n",
    "linear2 = nn.Linear(32,32,bias=True)\n",
    "linear3 = nn.Linear(32,32,bias=True)\n",
    "\n",
    "bn_linear1 = copy.deepcopy(linear1)\n",
    "bn_linear2 = copy.deepcopy(linear2)\n",
    "bn_linear3 = copy.deepcopy(linear3)\n",
    "\n",
    "class basic_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(basic_model, self).__init__()\n",
    "        self.fc1 = linear1\n",
    "        self.fc2 = linear2\n",
    "        self.fc3 = linear3\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        #print(out)\n",
    "        out = self.relu(out)\n",
    "        #print(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "class batchnorm_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(batchnorm_model,self).__init__()\n",
    "        self.fc1 = bn_linear1\n",
    "        self.fc2 = bn_linear2 \n",
    "        self.fc3 = bn_linear3\n",
    "        self.relu = nn.ReLU()\n",
    "        self.batch1 = nn.BatchNorm1d(32)\n",
    "        self.batch2 = nn.BatchNorm1d(32)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        #print(out)\n",
    "        out = self.batch1(out)\n",
    "        #print(out)\n",
    "        out = self.relu(out)\n",
    "        #print(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.batch2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0670, -0.0555, -0.1320,  ..., -0.2561,  0.4735,  0.2064],\n",
      "        [ 0.1682, -0.0104, -0.3163,  ...,  0.0014,  0.3961, -0.0819],\n",
      "        [-0.0427, -0.0915, -0.0578,  ..., -0.1353,  0.2736, -0.0332],\n",
      "        ...,\n",
      "        [-0.1127,  0.1074, -0.0797,  ..., -0.0825,  0.2056,  0.1114],\n",
      "        [-0.1161,  0.2110,  0.1304,  ..., -0.1562,  0.2155,  0.3483],\n",
      "        [-0.2512,  0.1737, -0.3614,  ...,  0.1445,  0.3043, -0.0791]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.4735, 0.2064],\n",
      "        [0.1682, 0.0000, 0.0000,  ..., 0.0014, 0.3961, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2736, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.1074, 0.0000,  ..., 0.0000, 0.2056, 0.1114],\n",
      "        [0.0000, 0.2110, 0.1304,  ..., 0.0000, 0.2155, 0.3483],\n",
      "        [0.0000, 0.1737, 0.0000,  ..., 0.1445, 0.3043, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "base_model = basic_model()\n",
    "\n",
    "for epoch in range(1):\n",
    "    for X,Y in train_loader:\n",
    "        X = X.view(-1, 28*28)\n",
    "        Y = Y\n",
    "\n",
    "        base_predict = base_model(X)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0670, -0.0555, -0.1320,  ..., -0.2561,  0.4735,  0.2064],\n",
      "        [ 0.1682, -0.0104, -0.3163,  ...,  0.0014,  0.3961, -0.0819],\n",
      "        [-0.0427, -0.0915, -0.0578,  ..., -0.1353,  0.2736, -0.0332],\n",
      "        ...,\n",
      "        [-0.1127,  0.1074, -0.0797,  ..., -0.0825,  0.2056,  0.1114],\n",
      "        [-0.1161,  0.2110,  0.1304,  ..., -0.1562,  0.2155,  0.3483],\n",
      "        [-0.2512,  0.1737, -0.3614,  ...,  0.1445,  0.3043, -0.0791]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1685, -0.8580, -0.4417,  ..., -1.1178,  0.5969,  0.8132],\n",
      "        [ 2.5056, -0.5298, -1.9844,  ...,  0.6609,  0.1511, -1.4087],\n",
      "        [ 0.4094, -1.1212,  0.1799,  ..., -0.2836, -0.5552, -1.0334],\n",
      "        ...,\n",
      "        [-0.2856,  0.3293, -0.0037,  ...,  0.0814, -0.9466,  0.0808],\n",
      "        [-0.3195,  1.0852,  1.7550,  ..., -0.4279, -0.8899,  1.9069],\n",
      "        [-1.6618,  0.8131, -2.3615,  ...,  1.6497, -0.3779, -1.3873]],\n",
      "       grad_fn=<NativeBatchNormBackward>)\n",
      "tensor([[0.1685, 0.0000, 0.0000,  ..., 0.0000, 0.5969, 0.8132],\n",
      "        [2.5056, 0.0000, 0.0000,  ..., 0.6609, 0.1511, 0.0000],\n",
      "        [0.4094, 0.0000, 0.1799,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.3293, 0.0000,  ..., 0.0814, 0.0000, 0.0808],\n",
      "        [0.0000, 1.0852, 1.7550,  ..., 0.0000, 0.0000, 1.9069],\n",
      "        [0.0000, 0.8131, 0.0000,  ..., 1.6497, 0.0000, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "bn_model = batchnorm_model()\n",
    "\n",
    "for epoch in range(1):\n",
    "    for X,Y in train_loader:\n",
    "        X = X.view(-1, 28*28)\n",
    "        Y = Y\n",
    "\n",
    "        bn_model_predict = bn_model(X)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2043,  0.1692, -0.2637,  ...,  0.0716, -0.0338, -0.1105],\n",
      "        [ 0.1196, -0.0432, -0.3785,  ..., -0.1595, -0.2196, -0.1844],\n",
      "        [ 0.2596,  0.1648, -0.2030,  ...,  0.0782,  0.0024,  0.2941],\n",
      "        ...,\n",
      "        [ 0.1171,  0.0896, -0.1296,  ..., -0.1014,  0.1282,  0.0279],\n",
      "        [ 0.2528,  0.3887, -0.0553,  ...,  0.1406, -0.1135, -0.1309],\n",
      "        [ 0.2885,  0.0699, -0.1020,  ..., -0.2190, -0.1932,  0.0370]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[0.2043, 0.1692, 0.0000,  ..., 0.0716, 0.0000, 0.0000],\n",
      "        [0.1196, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.2596, 0.1648, 0.0000,  ..., 0.0782, 0.0024, 0.2941],\n",
      "        ...,\n",
      "        [0.1171, 0.0896, 0.0000,  ..., 0.0000, 0.1282, 0.0279],\n",
      "        [0.2528, 0.3887, 0.0000,  ..., 0.1406, 0.0000, 0.0000],\n",
      "        [0.2885, 0.0699, 0.0000,  ..., 0.0000, 0.0000, 0.0370]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "base_model = basic_model()\n",
    "base_criterion = torch.nn.CrossEntropyLoss()\n",
    "base_optimizer = optim.Adam(base_model.parameters(), lr=0.001)\n",
    "\n",
    "base_train_loss = []\n",
    "base_test_loss = []\n",
    "\n",
    "for epoch in range(1):\n",
    "    base_model.train()\n",
    "\n",
    "    for X,Y in train_loader:\n",
    "        X = X.view(-1, 28*28)\n",
    "        Y = Y\n",
    "\n",
    "        base_optimizer.zero_grad()\n",
    "        base_predict = base_model(X)\n",
    "        base_loss = base_criterion(base_predict, Y)\n",
    "        base_loss.backward()\n",
    "        base_optimizer.step()\n",
    "\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2043,  0.1692, -0.2637,  ...,  0.0716, -0.0338, -0.1105],\n",
      "        [ 0.1196, -0.0432, -0.3785,  ..., -0.1595, -0.2196, -0.1844],\n",
      "        [ 0.2596,  0.1648, -0.2030,  ...,  0.0782,  0.0024,  0.2941],\n",
      "        ...,\n",
      "        [ 0.1171,  0.0896, -0.1296,  ..., -0.1014,  0.1282,  0.0279],\n",
      "        [ 0.2528,  0.3887, -0.0553,  ...,  0.1406, -0.1135, -0.1309],\n",
      "        [ 0.2885,  0.0699, -0.1020,  ..., -0.2190, -0.1932,  0.0370]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.0351,  0.1027, -0.8657,  ...,  1.3190,  0.1238, -0.6274],\n",
      "        [-0.4573, -1.2641, -1.7105,  ..., -0.6838, -1.3204, -1.2008],\n",
      "        [ 0.3563,  0.0739, -0.4195,  ...,  1.3762,  0.4047,  2.5129],\n",
      "        ...,\n",
      "        [-0.4716, -0.4099,  0.1206,  ..., -0.1801,  1.3831,  0.4468],\n",
      "        [ 0.3169,  1.5144,  0.6671,  ...,  1.9168, -0.4957, -0.7852],\n",
      "        [ 0.5246, -0.5361,  0.3234,  ..., -1.1995, -1.1154,  0.5180]],\n",
      "       grad_fn=<NativeBatchNormBackward>)\n",
      "tensor([[0.0351, 0.1027, 0.0000,  ..., 1.3190, 0.1238, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.3563, 0.0739, 0.0000,  ..., 1.3762, 0.4047, 2.5129],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.1206,  ..., 0.0000, 1.3831, 0.4468],\n",
      "        [0.3169, 1.5144, 0.6671,  ..., 1.9168, 0.0000, 0.0000],\n",
      "        [0.5246, 0.0000, 0.3234,  ..., 0.0000, 0.0000, 0.5180]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bn_model = batchnorm_model()\n",
    "bn_criterion = torch.nn.CrossEntropyLoss()\n",
    "bn_optimizer = optim.Adam(bn_model.parameters(), lr=0.001)\n",
    "\n",
    "bn_train_loss = []\n",
    "bn_test_loss = []\n",
    "\n",
    "for epoch in range(1):\n",
    "    bn_model.train()\n",
    "\n",
    "    for X,Y in train_loader:\n",
    "        X = X.view(-1, 28*28)\n",
    "        Y = Y\n",
    "\n",
    "        bn_optimizer.zero_grad()\n",
    "        bn_predict = bn_model(X)\n",
    "        bn_loss = bn_criterion(bn_predict, Y)\n",
    "        bn_loss.backward()\n",
    "        bn_optimizer.step()\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight\n",
      "tensor([[ 0.0184, -0.0158, -0.0069,  ...,  0.0068, -0.0041,  0.0025],\n",
      "        [-0.0274, -0.0224, -0.0309,  ..., -0.0029,  0.0013, -0.0167],\n",
      "        [ 0.0282, -0.0095, -0.0340,  ..., -0.0141,  0.0056, -0.0335],\n",
      "        ...,\n",
      "        [ 0.0226,  0.0331,  0.0182,  ...,  0.0150,  0.0278, -0.0073],\n",
      "        [-0.0210,  0.0144,  0.0214,  ..., -0.0308, -0.0335,  0.0085],\n",
      "        [ 0.0219,  0.0195, -0.0009,  ...,  0.0191,  0.0218, -0.0320]])\n",
      "fc1.bias\n",
      "tensor([-0.0307, -0.0331, -0.0263, -0.0178, -0.0344,  0.0138,  0.0016, -0.0208,\n",
      "         0.0306, -0.0286,  0.0310,  0.0326,  0.0169,  0.0296,  0.0092, -0.0179,\n",
      "         0.0081,  0.0100, -0.0235, -0.0033,  0.0248,  0.0040, -0.0298,  0.0020,\n",
      "        -0.0164, -0.0129, -0.0136, -0.0267, -0.0161,  0.0283,  0.0218,  0.0234])\n",
      "fc2.weight\n",
      "tensor([[-0.1084, -0.1104,  0.1025,  ...,  0.0448,  0.0729,  0.1699],\n",
      "        [-0.0593, -0.1072,  0.1283,  ..., -0.0471,  0.0327, -0.1190],\n",
      "        [-0.1477, -0.1216,  0.0104,  ...,  0.0205,  0.0137, -0.1070],\n",
      "        ...,\n",
      "        [-0.1121,  0.0123, -0.0682,  ..., -0.1026,  0.1203, -0.0791],\n",
      "        [-0.0191,  0.0246,  0.1755,  ..., -0.1550,  0.1343,  0.0649],\n",
      "        [ 0.0704,  0.1165,  0.0312,  ...,  0.1136,  0.1464, -0.0589]])\n",
      "fc2.bias\n",
      "tensor([ 0.0897,  0.0466, -0.1518, -0.0940, -0.0059,  0.1192,  0.0572, -0.0690,\n",
      "         0.0179,  0.1341, -0.0583, -0.1109, -0.0572,  0.1346,  0.0417,  0.0604,\n",
      "         0.0227,  0.1450,  0.1087,  0.0556,  0.0776,  0.0050,  0.1256, -0.0187,\n",
      "         0.1405,  0.0324,  0.1331,  0.0555, -0.0319,  0.0147, -0.1120, -0.1174])\n",
      "fc3.weight\n",
      "tensor([[-0.1492,  0.1563, -0.1242,  ...,  0.1630,  0.1054,  0.0210],\n",
      "        [ 0.1698, -0.1469, -0.0027,  ..., -0.1129, -0.1386,  0.1146],\n",
      "        [ 0.1621,  0.1153, -0.1494,  ..., -0.1035, -0.1642,  0.0960],\n",
      "        ...,\n",
      "        [ 0.0311,  0.0265,  0.1533,  ..., -0.0751, -0.0072,  0.0032],\n",
      "        [ 0.1186,  0.0438,  0.1389,  ..., -0.1700, -0.0386,  0.1093],\n",
      "        [-0.0979,  0.0015,  0.0385,  ...,  0.0289,  0.1272,  0.1079]])\n",
      "fc3.bias\n",
      "tensor([ 0.0621, -0.0485, -0.0582, -0.0848, -0.1148, -0.0081, -0.0594,  0.1474,\n",
      "        -0.1254, -0.1439,  0.1550, -0.0987,  0.1030,  0.0665, -0.0222,  0.1360,\n",
      "         0.0052, -0.0843,  0.0291,  0.0791,  0.1051, -0.0080,  0.0788,  0.1028,\n",
      "        -0.0258, -0.0891, -0.1780,  0.1291, -0.0454,  0.0049,  0.0629,  0.0189])\n",
      "fc1.weight\n",
      "tensor([[ 0.0184, -0.0158, -0.0069,  ...,  0.0068, -0.0041,  0.0025],\n",
      "        [-0.0274, -0.0224, -0.0309,  ..., -0.0029,  0.0013, -0.0167],\n",
      "        [ 0.0282, -0.0095, -0.0340,  ..., -0.0141,  0.0056, -0.0335],\n",
      "        ...,\n",
      "        [ 0.0226,  0.0331,  0.0182,  ...,  0.0150,  0.0278, -0.0073],\n",
      "        [-0.0210,  0.0144,  0.0214,  ..., -0.0308, -0.0335,  0.0085],\n",
      "        [ 0.0219,  0.0195, -0.0009,  ...,  0.0191,  0.0218, -0.0320]])\n",
      "fc1.bias\n",
      "tensor([-0.0307, -0.0331, -0.0263, -0.0178, -0.0344,  0.0138,  0.0016, -0.0208,\n",
      "         0.0306, -0.0286,  0.0310,  0.0326,  0.0169,  0.0296,  0.0092, -0.0179,\n",
      "         0.0081,  0.0100, -0.0235, -0.0033,  0.0248,  0.0040, -0.0298,  0.0020,\n",
      "        -0.0164, -0.0129, -0.0136, -0.0267, -0.0161,  0.0283,  0.0218,  0.0234])\n",
      "fc2.weight\n",
      "tensor([[-0.1084, -0.1104,  0.1025,  ...,  0.0448,  0.0729,  0.1699],\n",
      "        [-0.0593, -0.1072,  0.1283,  ..., -0.0471,  0.0327, -0.1190],\n",
      "        [-0.1477, -0.1216,  0.0104,  ...,  0.0205,  0.0137, -0.1070],\n",
      "        ...,\n",
      "        [-0.1121,  0.0123, -0.0682,  ..., -0.1026,  0.1203, -0.0791],\n",
      "        [-0.0191,  0.0246,  0.1755,  ..., -0.1550,  0.1343,  0.0649],\n",
      "        [ 0.0704,  0.1165,  0.0312,  ...,  0.1136,  0.1464, -0.0589]])\n",
      "fc2.bias\n",
      "tensor([ 0.0897,  0.0466, -0.1518, -0.0940, -0.0059,  0.1192,  0.0572, -0.0690,\n",
      "         0.0179,  0.1341, -0.0583, -0.1109, -0.0572,  0.1346,  0.0417,  0.0604,\n",
      "         0.0227,  0.1450,  0.1087,  0.0556,  0.0776,  0.0050,  0.1256, -0.0187,\n",
      "         0.1405,  0.0324,  0.1331,  0.0555, -0.0319,  0.0147, -0.1120, -0.1174])\n",
      "fc3.weight\n",
      "tensor([[-0.1492,  0.1563, -0.1242,  ...,  0.1630,  0.1054,  0.0210],\n",
      "        [ 0.1698, -0.1469, -0.0027,  ..., -0.1129, -0.1386,  0.1146],\n",
      "        [ 0.1621,  0.1153, -0.1494,  ..., -0.1035, -0.1642,  0.0960],\n",
      "        ...,\n",
      "        [ 0.0311,  0.0265,  0.1533,  ..., -0.0751, -0.0072,  0.0032],\n",
      "        [ 0.1186,  0.0438,  0.1389,  ..., -0.1700, -0.0386,  0.1093],\n",
      "        [-0.0979,  0.0015,  0.0385,  ...,  0.0289,  0.1272,  0.1079]])\n",
      "fc3.bias\n",
      "tensor([ 0.0621, -0.0485, -0.0582, -0.0848, -0.1148, -0.0081, -0.0594,  0.1474,\n",
      "        -0.1254, -0.1439,  0.1550, -0.0987,  0.1030,  0.0665, -0.0222,  0.1360,\n",
      "         0.0052, -0.0843,  0.0291,  0.0791,  0.1051, -0.0080,  0.0788,  0.1028,\n",
      "        -0.0258, -0.0891, -0.1780,  0.1291, -0.0454,  0.0049,  0.0629,  0.0189])\n",
      "batch1.weight\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "batch1.bias\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "batch1.running_mean\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "batch1.running_var\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "batch1.num_batches_tracked\n",
      "tensor(0)\n",
      "batch2.weight\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "batch2.bias\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "batch2.running_mean\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "batch2.running_var\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "batch2.num_batches_tracked\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "for names in base_model.state_dict():\n",
    "    print(names)\n",
    "    print(base_model.state_dict()[names])\n",
    "\n",
    "for name in bn_model.state_dict():\n",
    "    print(name)\n",
    "    print(bn_model.state_dict()[name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train loss vs Test loss 비교하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1875"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 cost:  5.057408634456806e-05\n",
      "epoch:  1 cost:  1.9800858353846706e-05\n",
      "epoch:  2 cost:  1.3690491869056132e-05\n",
      "epoch:  3 cost:  1.1773519872804172e-05\n",
      "epoch:  4 cost:  1.6117228369694203e-05\n",
      "epoch:  5 cost:  1.7431439118809067e-05\n",
      "epoch:  6 cost:  1.5606561646563932e-05\n",
      "epoch:  7 cost:  1.7677084542810917e-05\n",
      "epoch:  8 cost:  1.6763293388066813e-05\n",
      "epoch:  9 cost:  1.4744530744792428e-05\n",
      "epoch:  10 cost:  1.22299925351399e-05\n",
      "epoch:  11 cost:  1.0585506061033811e-05\n",
      "epoch:  12 cost:  1.123619222198613e-05\n",
      "epoch:  13 cost:  9.816709280130453e-06\n",
      "epoch:  14 cost:  7.574075425509363e-06\n"
     ]
    }
   ],
   "source": [
    "base_model = basic_model()\n",
    "base_criterion = torch.nn.CrossEntropyLoss()\n",
    "base_optimizer = optim.Adam(base_model.parameters(), lr=0.001)\n",
    "\n",
    "base_train_loss = []\n",
    "base_test_loss = []\n",
    "\n",
    "for epoch in range(15):\n",
    "    base_model.train()\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X,Y in train_loader:\n",
    "        X = X.view(-1, 28*28)\n",
    "        Y = Y\n",
    "\n",
    "        base_optimizer.zero_grad()\n",
    "        base_predict = base_model(X)\n",
    "        base_loss = base_criterion(base_predict, Y)\n",
    "        base_loss.backward()\n",
    "        base_optimizer.step()\n",
    "\n",
    "    avg_cost += base_loss / len(train_loader)\n",
    "    base_train_loss.append(avg_cost.item())\n",
    "\n",
    "    print('epoch: ', epoch, 'cost: ', avg_cost.item() )\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.162463978398591e-05,\n",
       " 3.775424920604564e-05,\n",
       " 1.9667701053549536e-05,\n",
       " 1.3259685147204436e-05,\n",
       " 1.0538067726884037e-05,\n",
       " 8.068742317846045e-06,\n",
       " 6.615039183088811e-06,\n",
       " 6.827609922765987e-06,\n",
       " 6.708504315611208e-06,\n",
       " 5.4978104344627354e-06,\n",
       " 6.794320142944343e-06,\n",
       " 5.0577095862536225e-06,\n",
       " 6.226142886589514e-06,\n",
       " 1.1537786122062244e-05,\n",
       " 6.850424597359961e-06]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(range(15),base_train_loss)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5777bc8a7577125a1c00ed1671130ea029cae56addc813f4c39a4f837e26f28b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('main': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
