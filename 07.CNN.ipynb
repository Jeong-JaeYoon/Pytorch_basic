{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pytorch로 시작하는 딥러닝 입문"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CNN으로 MNIST 분류하기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "inputs = torch.Tensor(1,1,28,28)\r\n",
    "print('텐서의 크기 {}'.format(inputs.shape))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "텐서의 크기 torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "conv1 = nn.Conv2d(1, 32, 3, padding=1)\r\n",
    "print(conv1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "conv2 = nn.Conv2d(32, 64, 3, padding=1)\r\n",
    "print(conv2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "pool = nn.MaxPool2d(kernel_size=2, stride=2)\r\n",
    "print(pool)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "out = conv1(inputs)\r\n",
    "print(out.shape)\r\n",
    "out = pool(out)\r\n",
    "print(out.shape)\r\n",
    "out = conv2(out)\r\n",
    "print(out.shape)\r\n",
    "out = pool(out)\r\n",
    "print(out.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 32, 28, 28])\n",
      "torch.Size([1, 32, 14, 14])\n",
      "torch.Size([1, 64, 14, 14])\n",
      "torch.Size([1, 64, 7, 7])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "out = out.view(out.size(0), -1)\r\n",
    "print(out.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 3136])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "fc = nn.Linear(3136, 10)\r\n",
    "out = fc(out)\r\n",
    "print(out.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import torchvision.datasets as dsets\r\n",
    "import torchvision.transforms as transforms\r\n",
    "import torch.nn.init\r\n",
    "\r\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
    "\r\n",
    "torch.manual_seed(777)\r\n",
    "if device == 'cuda':\r\n",
    "    torch.cuda.manual_seed_all(777)\r\n",
    "\r\n",
    "learning_rate = 0.001\r\n",
    "training_epoch = 15\r\n",
    "batch_size = 100\r\n",
    "\r\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/', train=True, transform=transforms.ToTensor(), download=True)\r\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/', train=False, transform=transforms.ToTensor, download=True)\r\n",
    "\r\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\r\n",
    "\r\n",
    "class CNN(torch.nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(CNN,self).__init__()\r\n",
    "        self.layer1 = torch.nn.Sequential(torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\r\n",
    "                                          torch.nn.ReLU(),\r\n",
    "                                          torch.nn.MaxPool2d(kernel_size=2, stride=2))\r\n",
    "        self.layer2 = torch.nn.Sequential(torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\r\n",
    "                                          torch.nn.ReLU(),\r\n",
    "                                          torch.nn.MaxPool2d(kernel_size=2, stride=2))\r\n",
    "        self.fc = torch.nn.Linear(7*7*64, 10, bias=True)\r\n",
    "\r\n",
    "        torch.nn.init.xavier_uniform_(self.fc.weight)\r\n",
    "    \r\n",
    "    def forward(self, x):\r\n",
    "        out = self.layer1(x)\r\n",
    "        out = self.layer2(out)\r\n",
    "        out = out.view(out.size(0), -1)\r\n",
    "        out = self.fc(out)\r\n",
    "        return out\r\n",
    "\r\n",
    "model = CNN().to(device)\r\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\r\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\r\n",
    "\r\n",
    "total_batch = len(data_loader)\r\n",
    "print('총 배치의 수 : {}'.format(total_batch))\r\n",
    "\r\n",
    "for epoch in range(training_epoch):\r\n",
    "    avg_cost = 0\r\n",
    "\r\n",
    "    for X,Y in data_loader:\r\n",
    "        \r\n",
    "        X = X.to(device)\r\n",
    "        Y = Y.to(device)\r\n",
    "        \r\n",
    "        optimizer.zero_grad()\r\n",
    "        hypothesis = model(X)\r\n",
    "        cost = criterion(hypothesis, Y)\r\n",
    "        cost.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        avg_cost += cost / total_batch\r\n",
    "    \r\n",
    "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch+1, avg_cost))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.4%"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "102.8%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "112.7%"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "C:\\Users\\DMQA\\anaconda3\\envs\\main\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "총 배치의 수 : 600\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\DMQA\\anaconda3\\envs\\main\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Epoch:    1] cost = 0.225672901\n",
      "[Epoch:    2] cost = 0.0630123764\n",
      "[Epoch:    3] cost = 0.0462936237\n",
      "[Epoch:    4] cost = 0.0374366343\n",
      "[Epoch:    5] cost = 0.0313647017\n",
      "[Epoch:    6] cost = 0.0259269103\n",
      "[Epoch:    7] cost = 0.0217944086\n",
      "[Epoch:    8] cost = 0.018254742\n",
      "[Epoch:    9] cost = 0.0160853639\n",
      "[Epoch:   10] cost = 0.0130002331\n",
      "[Epoch:   11] cost = 0.0100359023\n",
      "[Epoch:   12] cost = 0.00994346477\n",
      "[Epoch:   13] cost = 0.00847206544\n",
      "[Epoch:   14] cost = 0.00614511687\n",
      "[Epoch:   15] cost = 0.00664831512\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "with torch.no_grad():\r\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\r\n",
    "    Y_test = mnist_test.test_labels.to(device)\r\n",
    "\r\n",
    "    predict = model(X_test)\r\n",
    "    correct_predict = torch.argmax(predict, 1) == Y_test\r\n",
    "    accuracy = correct_predict.float().mean()\r\n",
    "    print('Accuracy:', accuracy.item())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\DMQA\\anaconda3\\envs\\main\\lib\\site-packages\\torchvision\\datasets\\mnist.py:67: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\Users\\DMQA\\anaconda3\\envs\\main\\lib\\site-packages\\torchvision\\datasets\\mnist.py:57: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.9873999953269958\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CNN층 많이 쌓아서 MNIST 분류하기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import torch\r\n",
    "import torchvision.datasets as dsets\r\n",
    "import torchvision.transforms as transforms\r\n",
    "import torch.nn.init\r\n",
    "\r\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
    "\r\n",
    "torch.manual_seed(777)\r\n",
    "\r\n",
    "if device == 'cuda':\r\n",
    "    torch.cuda.manual_seed_all(777)\r\n",
    "\r\n",
    "learning_rate = 0.001\r\n",
    "training_epoch = 15\r\n",
    "batch_size = 100\r\n",
    "\r\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/', train=True, transform=transforms.ToTensor(), download=True)\r\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/', train=False, transform=transforms.ToTensor(), download=True)\r\n",
    "\r\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\r\n",
    "\r\n",
    "class CNN(torch.nn.Module):\r\n",
    "    \r\n",
    "    def __init__(self):\r\n",
    "        super(CNN, self).__init__()\r\n",
    "        self.layer1 = torch.nn.Sequential(torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1), \r\n",
    "                                          torch.nn.ReLU(),\r\n",
    "                                          torch.nn.MaxPool2d(kernel_size=2,stride=2))\r\n",
    "        self.layer2 = torch.nn.Sequential(torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\r\n",
    "                                          torch.nn.ReLU(),\r\n",
    "                                          torch.nn.MaxPool2d(kernel_size=2, stride=2))\r\n",
    "        self.layer3 = torch.nn.Sequential(torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\r\n",
    "                                          torch.nn.ReLU(),\r\n",
    "                                          torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1))\r\n",
    "        self.fc1 = torch.nn.Linear(128*4*4, 625, bias=True)\r\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\r\n",
    "        self.layer4 = torch.nn.Sequential(self.fc1, torch.nn.ReLU(), torch.nn.Dropout(0.5))\r\n",
    "        self.fc2 = torch.nn.Linear(625, 10, bias=True)\r\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        out = self.layer1(x)\r\n",
    "        out = self.layer2(out)\r\n",
    "        out = self.layer3(out)\r\n",
    "        out = out.view(out.size(0), -1)\r\n",
    "        out = self.layer4(out)\r\n",
    "        out = self.fc2(out)\r\n",
    "        return out\r\n",
    "\r\n",
    "model = CNN().to(device)\r\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\r\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\r\n",
    "total_batch = len(data_loader)\r\n",
    "print('총 배치의 수 : {}'.format(total_batch))\r\n",
    "\r\n",
    "for epoch in range(training_epoch):\r\n",
    "    avg_cost = 0\r\n",
    "\r\n",
    "    for X,Y in data_loader:\r\n",
    "\r\n",
    "        X = X.to(device)\r\n",
    "        Y = Y.to(device)\r\n",
    "\r\n",
    "        optimizer.zero_grad()\r\n",
    "        hypothesis = model(X)\r\n",
    "        loss = criterion(hypothesis, Y)\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        avg_cost += loss / total_batch\r\n",
    "\r\n",
    "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "총 배치의 수 : 600\n",
      "[Epoch:    1] cost = 0.19165121\n",
      "[Epoch:    2] cost = 0.0533648394\n",
      "[Epoch:    3] cost = 0.0366143063\n",
      "[Epoch:    4] cost = 0.0300903078\n",
      "[Epoch:    5] cost = 0.023340499\n",
      "[Epoch:    6] cost = 0.020813629\n",
      "[Epoch:    7] cost = 0.0181835592\n",
      "[Epoch:    8] cost = 0.0147469668\n",
      "[Epoch:    9] cost = 0.0125557734\n",
      "[Epoch:   10] cost = 0.0115145333\n",
      "[Epoch:   11] cost = 0.0105969142\n",
      "[Epoch:   12] cost = 0.00887154602\n",
      "[Epoch:   13] cost = 0.00928252842\n",
      "[Epoch:   14] cost = 0.007214271\n",
      "[Epoch:   15] cost = 0.00594375655\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "with torch.no_grad():\r\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\r\n",
    "    Y_test = mnist_test.test_labels.to(device)\r\n",
    "\r\n",
    "    predict = model(X_test)\r\n",
    "    correct_predict = torch.argmax(predict, 1) == Y_test\r\n",
    "    accuracy = correct_predict.float().mean()\r\n",
    "    print('Accuracy : ', accuracy.item())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\DMQA\\anaconda3\\envs\\main\\lib\\site-packages\\torchvision\\datasets\\mnist.py:67: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\Users\\DMQA\\anaconda3\\envs\\main\\lib\\site-packages\\torchvision\\datasets\\mnist.py:57: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy :  0.9793999791145325\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('main': conda)"
  },
  "interpreter": {
   "hash": "5777bc8a7577125a1c00ed1671130ea029cae56addc813f4c39a4f837e26f28b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}