{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pytorch로 시작하는 딥러닝 입문"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 텐서 조작하기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "t = torch.FloatTensor([0., 1., 2., 3., 4., 5., 6,])\r\n",
    "print(t)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([0., 1., 2., 3., 4., 5., 6.])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "print(t.dim())\r\n",
    "print(t.shape)\r\n",
    "print(t.size())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "torch.Size([7])\n",
      "torch.Size([7])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "print(t[0], t[2:5], t[:])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(0.) tensor([2., 3., 4.]) tensor([0., 1., 2., 3., 4., 5., 6.])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "t = torch.FloatTensor([[1.,2.,3.], [4.,5.,6.,], [7.,8.,9.], [10.,11.,12.]])\r\n",
    "print(t)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "print(t.dim())\r\n",
    "print(t.size())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "print(t[:,1])\r\n",
    "print(t[:,1].size())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([ 2.,  5.,  8., 11.])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "print(t[:,:-1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 1.,  2.],\n",
      "        [ 4.,  5.],\n",
      "        [ 7.,  8.],\n",
      "        [10., 11.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "m1 = torch.FloatTensor([[1,2], [3,4]])\r\n",
    "m2 = torch.FloatTensor([[1], [2]])\r\n",
    "\r\n",
    "print('shape of matrix 1: ', m1.shape)\r\n",
    "print('shape of matrix 2: ', m2.size())\r\n",
    "print(m1.matmul(m2))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "shape of matrix 1:  torch.Size([2, 2])\n",
      "shape of matrix 2:  torch.Size([2, 1])\n",
      "tensor([[ 5.],\n",
      "        [11.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "print(m1*m2)\r\n",
    "print(m1.mul(m2))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1., 2.],\n",
      "        [6., 8.]])\n",
      "tensor([[1., 2.],\n",
      "        [6., 8.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "matmul은 element-wise를 의미하고, *이나 mul은 그냥 행렬곱을 의미함"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "t = torch.FloatTensor([1,2])\r\n",
    "print(t.mean())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(1.5000)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "t = torch.FloatTensor([[1,2], [3,4]])\r\n",
    "print(t.mean())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(2.5000)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "print(t.mean(dim=0))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([2., 3.])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "t = torch.FloatTensor([[1,2], [3,4]])\r\n",
    "print(t.sum())\r\n",
    "print(t.sum(dim=0))\r\n",
    "print(t.sum(dim=1))\r\n",
    "print(t.sum(dim=-1))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(10.)\n",
      "tensor([4., 6.])\n",
      "tensor([3., 7.])\n",
      "tensor([3., 7.])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "print(t.max(dim=0))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([3., 4.]),\n",
      "indices=tensor([1, 1]))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "docs에서는 argmax를 단순히 max를 통해서 구할 수 있다고 쓰여져 있는데 사실 걍 t.argmax를 사용해도 값은 나옴"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "t = np.array([[[0,1,2], [3,4,5]],[[6,7,8],[9,10,11]]])\r\n",
    "ft = torch.FloatTensor(t)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "print(ft.shape)\r\n",
    "print(ft)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "tensor([[[ 0.,  1.,  2.],\n",
      "         [ 3.,  4.,  5.]],\n",
      "\n",
      "        [[ 6.,  7.,  8.],\n",
      "         [ 9., 10., 11.]]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "print(ft.view([-1,3]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 0.,  1.,  2.],\n",
      "        [ 3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.],\n",
      "        [ 9., 10., 11.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "print(ft.view([-1,1,3]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[ 0.,  1.,  2.]],\n",
      "\n",
      "        [[ 3.,  4.,  5.]],\n",
      "\n",
      "        [[ 6.,  7.,  8.]],\n",
      "\n",
      "        [[ 9., 10., 11.]]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "ft"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  2.],\n",
       "         [ 3.,  4.,  5.]],\n",
       "\n",
       "        [[ 6.,  7.,  8.],\n",
       "         [ 9., 10., 11.]]])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "여전히 ft는 변함 없음을 확인함"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "ft = torch.FloatTensor([[0],[1],[2]])\r\n",
    "print(ft)\r\n",
    "print(ft.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "print(ft.squeeze())\r\n",
    "print(ft.squeeze().shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([0., 1., 2.])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "print(ft.unsqueeze(-1))\r\n",
    "print(ft.unsqueeze(-1).shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[0.]],\n",
      "\n",
      "        [[1.]],\n",
      "\n",
      "        [[2.]]])\n",
      "torch.Size([3, 1, 1])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "사실상 unsqueeze안에 들어가는 값은 인덱스나 다름없음"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "view(), squeeze(), unsqueeze() 모두 텐서의 원소는 그대로 두고 텐서의 차원을 바꾸어 주는 함수들임"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "lt = torch.LongTensor([1,2,3,4])\r\n",
    "print(lt)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([1, 2, 3, 4])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "print(lt.float())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([1., 2., 3., 4.])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "bt = torch.ByteTensor([True, False, False, True])\r\n",
    "print(bt)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([1, 0, 0, 1], dtype=torch.uint8)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "bt"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 1], dtype=torch.uint8)"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "x = torch.FloatTensor([[1,2], [3,4]])\r\n",
    "y = torch.FloatTensor([[5,6], [7,8]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "print(torch.cat([x,y]))\r\n",
    "print(torch.cat([x,y]).shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.],\n",
      "        [7., 8.]])\n",
      "torch.Size([4, 2])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "default는 dim = 0일 때이니 유의해두기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "print(torch.cat([x,y], dim = 1))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1., 2., 5., 6.],\n",
      "        [3., 4., 7., 8.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "x = torch.FloatTensor([1,4])\r\n",
    "y = torch.FloatTensor([2,5])\r\n",
    "z = torch.FloatTensor([3,6])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "print(torch.stack([x,y,z]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "print(torch.cat([x,y,z]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([1., 4., 2., 5., 3., 6.])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "단순 cat과 stack은 차이가 있음을 알아두자. cat은 tensor들을 병합하는 느낌이라면 stack은 단순히 쌓는 느낌"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "print(torch.stack([x,y,z], dim=1))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "x = torch.FloatTensor([[0,1,2], [2,1,0]])\r\n",
    "print(x)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0., 1., 2.],\n",
      "        [2., 1., 0.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "print(torch.ones_like(x))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "print(torch.zeros_like(x))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "x = torch.FloatTensor([[1,2], [3,4]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "print(x.mul(2.))\r\n",
    "print(x)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "print(x.mul_(2.))\r\n",
    "print(x)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n",
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 파이썬 클래스\r\n",
    "\r\n",
    "그냥 읽고 넘기기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 선형회귀"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "torch.manual_seed(1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x20380440ef0>"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "x_train = torch.FloatTensor([[1],[2],[3]])\r\n",
    "y_train = torch.FloatTensor([[2],[4],[6]])\r\n",
    "\r\n",
    "W = torch.zeros(1, requires_grad=True)\r\n",
    "b = torch.zeros(1, requires_grad=True)\r\n",
    "\r\n",
    "optimizer = optim.SGD([W,b], lr=0.01)\r\n",
    "\r\n",
    "epochs = 1999\r\n",
    "\r\n",
    "for epoch in range(epochs + 1):\r\n",
    "    \r\n",
    "    hypothesis = x_train*W + b\r\n",
    "\r\n",
    "    cost = torch.mean((hypothesis - y_train)**2)\r\n",
    "\r\n",
    "    optimizer.zero_grad()\r\n",
    "    cost.backward()\r\n",
    "    optimizer.step()\r\n",
    "\r\n",
    "    if epoch % 100 == 0:\r\n",
    "        print('Epoch {:2d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(epoch, epochs + 1, W.item(), b.item(), cost.item()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch  0/2000 W: 0.187, b: 0.080 Cost: 18.666666\n",
      "Epoch 100/2000 W: 1.746, b: 0.578 Cost: 0.048171\n",
      "Epoch 200/2000 W: 1.800, b: 0.454 Cost: 0.029767\n",
      "Epoch 300/2000 W: 1.843, b: 0.357 Cost: 0.018394\n",
      "Epoch 400/2000 W: 1.876, b: 0.281 Cost: 0.011366\n",
      "Epoch 500/2000 W: 1.903, b: 0.221 Cost: 0.007024\n",
      "Epoch 600/2000 W: 1.924, b: 0.174 Cost: 0.004340\n",
      "Epoch 700/2000 W: 1.940, b: 0.136 Cost: 0.002682\n",
      "Epoch 800/2000 W: 1.953, b: 0.107 Cost: 0.001657\n",
      "Epoch 900/2000 W: 1.963, b: 0.084 Cost: 0.001024\n",
      "Epoch 1000/2000 W: 1.971, b: 0.066 Cost: 0.000633\n",
      "Epoch 1100/2000 W: 1.977, b: 0.052 Cost: 0.000391\n",
      "Epoch 1200/2000 W: 1.982, b: 0.041 Cost: 0.000242\n",
      "Epoch 1300/2000 W: 1.986, b: 0.032 Cost: 0.000149\n",
      "Epoch 1400/2000 W: 1.989, b: 0.025 Cost: 0.000092\n",
      "Epoch 1500/2000 W: 1.991, b: 0.020 Cost: 0.000057\n",
      "Epoch 1600/2000 W: 1.993, b: 0.016 Cost: 0.000035\n",
      "Epoch 1700/2000 W: 1.995, b: 0.012 Cost: 0.000022\n",
      "Epoch 1800/2000 W: 1.996, b: 0.010 Cost: 0.000013\n",
      "Epoch 1900/2000 W: 1.997, b: 0.008 Cost: 0.000008\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "w = torch.tensor(2.0, requires_grad=True)\r\n",
    "\r\n",
    "z = 2*(w**2) + 5\r\n",
    "\r\n",
    "z.backward()\r\n",
    "\r\n",
    "print('z를 w로 미분한 값 : {}'.format(w.grad))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "z를 w로 미분한 값 : 8.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "x1_train = torch.FloatTensor([[73], [93], [89], [96], [73]])\r\n",
    "x2_train = torch.FloatTensor([[80], [88], [91], [98], [66]])\r\n",
    "x3_train = torch.FloatTensor([[75], [93], [90], [100], [70]])\r\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "w1 = torch.zeros(1, requires_grad=True)\r\n",
    "w2 = torch.zeros(1, requires_grad=True)\r\n",
    "w3 = torch.zeros(1, requires_grad=True)\r\n",
    "b = torch.zeros(1, requires_grad=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "optimizer = optim.SGD([w1,w2,w3,b], lr = 1e-5)\r\n",
    "\r\n",
    "np_epochs = 1000\r\n",
    "\r\n",
    "for epoch in range(np_epochs + 1):\r\n",
    "    \r\n",
    "    hypothesis = w1*x1_train + w2*x2_train + w3*x3_train + b\r\n",
    "\r\n",
    "    cost = torch.mean(((hypothesis - y_train)**2))\r\n",
    "\r\n",
    "    optimizer.zero_grad()\r\n",
    "    cost.backward()\r\n",
    "    optimizer.step()\r\n",
    "\r\n",
    "    if epoch % 100 == 0 :\r\n",
    "        print('Epoch {}/{} w1: {:.3f} w2: {:.3f} w3: {:.3f} b: {:.3f} Cost: {:.6f}'.format(epoch, np_epochs, w1.item(), w2.item(), w3.item(), b.item(), cost.item()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0/1000 w1: 0.294 w2: 0.294 w3: 0.297 b: 0.003 Cost: 29661.800781\n",
      "Epoch 100/1000 w1: 0.674 w2: 0.661 w3: 0.676 b: 0.008 Cost: 1.563634\n",
      "Epoch 200/1000 w1: 0.679 w2: 0.655 w3: 0.677 b: 0.008 Cost: 1.497607\n",
      "Epoch 300/1000 w1: 0.684 w2: 0.649 w3: 0.677 b: 0.008 Cost: 1.435026\n",
      "Epoch 400/1000 w1: 0.689 w2: 0.643 w3: 0.678 b: 0.008 Cost: 1.375730\n",
      "Epoch 500/1000 w1: 0.694 w2: 0.638 w3: 0.678 b: 0.009 Cost: 1.319511\n",
      "Epoch 600/1000 w1: 0.699 w2: 0.633 w3: 0.679 b: 0.009 Cost: 1.266222\n",
      "Epoch 700/1000 w1: 0.704 w2: 0.627 w3: 0.679 b: 0.009 Cost: 1.215696\n",
      "Epoch 800/1000 w1: 0.709 w2: 0.622 w3: 0.679 b: 0.009 Cost: 1.167818\n",
      "Epoch 900/1000 w1: 0.713 w2: 0.617 w3: 0.680 b: 0.009 Cost: 1.122429\n",
      "Epoch 1000/1000 w1: 0.718 w2: 0.613 w3: 0.680 b: 0.009 Cost: 1.079378\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "x_train = torch.FloatTensor([[73, 80, 75], [93, 88, 93], [89, 91, 80], [96, 98, 100], [73, 66, 70]])\r\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\r\n",
    "\r\n",
    "W = torch.zeros((3,1), requires_grad=True)\r\n",
    "b = torch.zeros(1, requires_grad=True)\r\n",
    "\r\n",
    "optimizer = optim.SGD([W,b], lr=1e-5)\r\n",
    "\r\n",
    "total_epochs = 20\r\n",
    "\r\n",
    "for epoch in range(total_epochs+1):\r\n",
    "    \r\n",
    "    hypothesis = x_train.matmul(W) + b\r\n",
    "\r\n",
    "    cost = torch.mean((hypothesis - y_train)**2)\r\n",
    "\r\n",
    "    optimizer.zero_grad()\r\n",
    "    cost.backward()\r\n",
    "    optimizer.step()\r\n",
    "\r\n",
    "    print('Epoch {}/{} hypothesis: {} Cost: {:.6f}'.format(epoch, total_epochs, hypothesis.squeeze().detach(), cost.item()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0/20 hypothesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
      "Epoch 1/20 hypothesis: tensor([66.7178, 80.1701, 76.1025, 86.0194, 61.1565]) Cost: 9537.694336\n",
      "Epoch 2/20 hypothesis: tensor([104.5421, 125.6208, 119.2478, 134.7862,  95.8280]) Cost: 3069.590088\n",
      "Epoch 3/20 hypothesis: tensor([125.9858, 151.3882, 143.7087, 162.4333, 115.4844]) Cost: 990.670898\n",
      "Epoch 4/20 hypothesis: tensor([138.1429, 165.9963, 157.5768, 178.1071, 126.6283]) Cost: 322.482086\n",
      "Epoch 5/20 hypothesis: tensor([145.0350, 174.2780, 165.4395, 186.9928, 132.9461]) Cost: 107.717064\n",
      "Epoch 6/20 hypothesis: tensor([148.9423, 178.9730, 169.8976, 192.0301, 136.5279]) Cost: 38.687496\n",
      "Epoch 7/20 hypothesis: tensor([151.1574, 181.6346, 172.4254, 194.8856, 138.5585]) Cost: 16.499043\n",
      "Epoch 8/20 hypothesis: tensor([152.4131, 183.1435, 173.8590, 196.5043, 139.7097]) Cost: 9.365656\n",
      "Epoch 9/20 hypothesis: tensor([153.1250, 183.9988, 174.6723, 197.4217, 140.3625]) Cost: 7.071114\n",
      "Epoch 10/20 hypothesis: tensor([153.5285, 184.4835, 175.1338, 197.9415, 140.7325]) Cost: 6.331847\n",
      "Epoch 11/20 hypothesis: tensor([153.7572, 184.7582, 175.3958, 198.2360, 140.9424]) Cost: 6.092532\n",
      "Epoch 12/20 hypothesis: tensor([153.8868, 184.9138, 175.5449, 198.4026, 141.0613]) Cost: 6.013817\n",
      "Epoch 13/20 hypothesis: tensor([153.9602, 185.0019, 175.6299, 198.4969, 141.1288]) Cost: 5.986785\n",
      "Epoch 14/20 hypothesis: tensor([154.0017, 185.0517, 175.6785, 198.5500, 141.1671]) Cost: 5.976325\n",
      "Epoch 15/20 hypothesis: tensor([154.0252, 185.0798, 175.7065, 198.5800, 141.1888]) Cost: 5.971208\n",
      "Epoch 16/20 hypothesis: tensor([154.0385, 185.0956, 175.7229, 198.5966, 141.2012]) Cost: 5.967835\n",
      "Epoch 17/20 hypothesis: tensor([154.0459, 185.1045, 175.7326, 198.6059, 141.2082]) Cost: 5.964969\n",
      "Epoch 18/20 hypothesis: tensor([154.0501, 185.1094, 175.7386, 198.6108, 141.2122]) Cost: 5.962291\n",
      "Epoch 19/20 hypothesis: tensor([154.0524, 185.1120, 175.7424, 198.6134, 141.2145]) Cost: 5.959664\n",
      "Epoch 20/20 hypothesis: tensor([154.0536, 185.1134, 175.7451, 198.6145, 141.2158]) Cost: 5.957089\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "detach()는 기본적으로 tensor를 복사하는 기능을 함. 위의 연습에서 알아둬야할 점은 기존 연산에서 추적되는 걸 방지하고 오로지 tensor 형태로만 뽑아온다는 것.  \r\n",
    "이해가 안가면 detach()를 하고 안하고를 한번씩 돌려보면 알 듯"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "torch.manual_seed(1)\r\n",
    "\r\n",
    "x_train = torch.FloatTensor([[1],[2],[3]])\r\n",
    "y_train = torch.FloatTensor([[2],[4],[6]])\r\n",
    "\r\n",
    "model = nn.Linear(1,1)\r\n",
    "\r\n",
    "print(list(model.parameters()))\r\n",
    "\r\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)\r\n",
    "\r\n",
    "total_epochs = 2000\r\n",
    "\r\n",
    "for epoch in range(total_epochs+1):\r\n",
    "\r\n",
    "    prediction = model(x_train)\r\n",
    "\r\n",
    "    cost = F.mse_loss(prediction, y_train)\r\n",
    "\r\n",
    "    optimizer.zero_grad()\r\n",
    "    cost.backward()\r\n",
    "    optimizer.step()\r\n",
    "\r\n",
    "    if epoch % 100 == 0:\r\n",
    "        print('Epoch {}/{} Cost: {:.6f}'.format(epoch, total_epochs, cost.item()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Parameter containing:\n",
      "tensor([[0.5153]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4414], requires_grad=True)]\n",
      "Epoch 0/2000 Cost: 13.103541\n",
      "Epoch 100/2000 Cost: 0.002791\n",
      "Epoch 200/2000 Cost: 0.001724\n",
      "Epoch 300/2000 Cost: 0.001066\n",
      "Epoch 400/2000 Cost: 0.000658\n",
      "Epoch 500/2000 Cost: 0.000407\n",
      "Epoch 600/2000 Cost: 0.000251\n",
      "Epoch 700/2000 Cost: 0.000155\n",
      "Epoch 800/2000 Cost: 0.000096\n",
      "Epoch 900/2000 Cost: 0.000059\n",
      "Epoch 1000/2000 Cost: 0.000037\n",
      "Epoch 1100/2000 Cost: 0.000023\n",
      "Epoch 1200/2000 Cost: 0.000014\n",
      "Epoch 1300/2000 Cost: 0.000009\n",
      "Epoch 1400/2000 Cost: 0.000005\n",
      "Epoch 1500/2000 Cost: 0.000003\n",
      "Epoch 1600/2000 Cost: 0.000002\n",
      "Epoch 1700/2000 Cost: 0.000001\n",
      "Epoch 1800/2000 Cost: 0.000001\n",
      "Epoch 1900/2000 Cost: 0.000000\n",
      "Epoch 2000/2000 Cost: 0.000000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "new_data = torch.FloatTensor([[4.0]])\r\n",
    "\r\n",
    "pred_y = model(new_data)\r\n",
    "print(pred_y)\r\n",
    "print(list(model.parameters()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[7.9989]], grad_fn=<AddmmBackward>)\n",
      "[Parameter containing:\n",
      "tensor([[1.9994]], requires_grad=True), Parameter containing:\n",
      "tensor([0.0014], requires_grad=True)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "개인적으로 왜 [[4.0]]을 선언하는지는 잘 모르겠음. 실제로 [4.0]을 넣어서 돌려봐도 값은 동일하게 나온다. 굳이 차원을 늘리는 이유는 차원을 맞춰주기 위함인가?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "torch.manual_seed(1)\r\n",
    "\r\n",
    "x_train = torch.FloatTensor([[73, 80, 75], [93, 88, 93], [89, 91, 80], [96, 98, 100], [73, 66, 70]])\r\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\r\n",
    "\r\n",
    "model = nn.Linear(3,1)\r\n",
    "\r\n",
    "print(model.parameters())\r\n",
    "\r\n",
    "optimizer = optim.SGD(model.parameters(),lr=1e-5)\r\n",
    "total_epochs = 2000\r\n",
    "\r\n",
    "for epoch in range(total_epochs+1):\r\n",
    "\r\n",
    "    prediction = model(x_train)\r\n",
    "    cost = F.mse_loss(prediction, y_train)\r\n",
    "\r\n",
    "    optimizer.zero_grad()\r\n",
    "    cost.backward()\r\n",
    "    optimizer.step()\r\n",
    "\r\n",
    "    if epoch % 100 == 0 :\r\n",
    "        print('Epoch {}/{} Cost: {}'.format(epoch, total_epochs, cost.item()))\r\n",
    "\r\n",
    "print(list(model.parameters()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<generator object Module.parameters at 0x00000203850B9DD0>\n",
      "Epoch 0/2000 Cost: 31584.34765625\n",
      "Epoch 100/2000 Cost: 4.054811477661133\n",
      "Epoch 200/2000 Cost: 3.8079185485839844\n",
      "Epoch 300/2000 Cost: 3.5776000022888184\n",
      "Epoch 400/2000 Cost: 3.3626468181610107\n",
      "Epoch 500/2000 Cost: 3.1620583534240723\n",
      "Epoch 600/2000 Cost: 2.9748358726501465\n",
      "Epoch 700/2000 Cost: 2.8000454902648926\n",
      "Epoch 800/2000 Cost: 2.6367905139923096\n",
      "Epoch 900/2000 Cost: 2.484294891357422\n",
      "Epoch 1000/2000 Cost: 2.3418288230895996\n",
      "Epoch 1100/2000 Cost: 2.208688735961914\n",
      "Epoch 1200/2000 Cost: 2.0842132568359375\n",
      "Epoch 1300/2000 Cost: 1.9678411483764648\n",
      "Epoch 1400/2000 Cost: 1.8590164184570312\n",
      "Epoch 1500/2000 Cost: 1.75718092918396\n",
      "Epoch 1600/2000 Cost: 1.6619274616241455\n",
      "Epoch 1700/2000 Cost: 1.572750449180603\n",
      "Epoch 1800/2000 Cost: 1.4892637729644775\n",
      "Epoch 1900/2000 Cost: 1.4110760688781738\n",
      "Epoch 2000/2000 Cost: 1.3378291130065918\n",
      "[Parameter containing:\n",
      "tensor([[1.0551, 0.5767, 0.3883]], requires_grad=True), Parameter containing:\n",
      "tensor([0.2791], requires_grad=True)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "class LinearRegression(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(LinearRegression, self).__init__()\r\n",
    "        self.linear = nn.Linear(1,1)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        return self.linear(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "torch.manual_seed(1)\r\n",
    "\r\n",
    "x_train = torch.FloatTensor([[1],[2],[3]])\r\n",
    "y_train = torch.FloatTensor([[2],[4],[6]])\r\n",
    "\r\n",
    "model = LinearRegression()\r\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)\r\n",
    "total_epochs = 2000\r\n",
    "\r\n",
    "for epoch in range(total_epochs+1):\r\n",
    "    \r\n",
    "    prediction = model(x_train)\r\n",
    "    cost = F.mse_loss(prediction, y_train)\r\n",
    "\r\n",
    "    optimizer.zero_grad()\r\n",
    "    cost.backward()\r\n",
    "    optimizer.step()\r\n",
    "\r\n",
    "    if epoch % 100 == 0:\r\n",
    "        print('Epoch {}/{} Cost: {:.6f}'.format(epoch, total_epochs, cost.item()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0/2000 Cost: 13.103541\n",
      "Epoch 100/2000 Cost: 0.002791\n",
      "Epoch 200/2000 Cost: 0.001724\n",
      "Epoch 300/2000 Cost: 0.001066\n",
      "Epoch 400/2000 Cost: 0.000658\n",
      "Epoch 500/2000 Cost: 0.000407\n",
      "Epoch 600/2000 Cost: 0.000251\n",
      "Epoch 700/2000 Cost: 0.000155\n",
      "Epoch 800/2000 Cost: 0.000096\n",
      "Epoch 900/2000 Cost: 0.000059\n",
      "Epoch 1000/2000 Cost: 0.000037\n",
      "Epoch 1100/2000 Cost: 0.000023\n",
      "Epoch 1200/2000 Cost: 0.000014\n",
      "Epoch 1300/2000 Cost: 0.000009\n",
      "Epoch 1400/2000 Cost: 0.000005\n",
      "Epoch 1500/2000 Cost: 0.000003\n",
      "Epoch 1600/2000 Cost: 0.000002\n",
      "Epoch 1700/2000 Cost: 0.000001\n",
      "Epoch 1800/2000 Cost: 0.000001\n",
      "Epoch 1900/2000 Cost: 0.000000\n",
      "Epoch 2000/2000 Cost: 0.000000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "class MultivariateLinearRegression(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(MultivariateLinearRegression, self).__init__()\r\n",
    "        self.linear = nn.Linear(3,1)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        return self.linear(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "torch.manual_seed(1)\r\n",
    "\r\n",
    "x_train = torch.FloatTensor([[73, 80, 75], [93, 88, 93], [89, 91, 80], [96, 98, 100], [73, 66, 70]])\r\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\r\n",
    "\r\n",
    "model = MultivariateLinearRegression()\r\n",
    "optimizer = optim.SGD(model.parameters(), lr = 1e-5)\r\n",
    "total_epochs = 2000\r\n",
    "\r\n",
    "for epoch in range(total_epochs+1):\r\n",
    "\r\n",
    "    prediction = model(x_train)\r\n",
    "    cost = F.mse_loss(prediction, y_train)\r\n",
    "\r\n",
    "    optimizer.zero_grad()\r\n",
    "    cost.backward()\r\n",
    "    optimizer.step()\r\n",
    "\r\n",
    "    if epoch % 100 == 0:\r\n",
    "        print('Epoch {}/{} Cost: {:.6f}'.format(epoch, total_epochs, cost.item()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0/2000 Cost: 31584.347656\n",
      "Epoch 100/2000 Cost: 4.054811\n",
      "Epoch 200/2000 Cost: 3.807919\n",
      "Epoch 300/2000 Cost: 3.577600\n",
      "Epoch 400/2000 Cost: 3.362647\n",
      "Epoch 500/2000 Cost: 3.162058\n",
      "Epoch 600/2000 Cost: 2.974836\n",
      "Epoch 700/2000 Cost: 2.800045\n",
      "Epoch 800/2000 Cost: 2.636791\n",
      "Epoch 900/2000 Cost: 2.484295\n",
      "Epoch 1000/2000 Cost: 2.341829\n",
      "Epoch 1100/2000 Cost: 2.208689\n",
      "Epoch 1200/2000 Cost: 2.084213\n",
      "Epoch 1300/2000 Cost: 1.967841\n",
      "Epoch 1400/2000 Cost: 1.859016\n",
      "Epoch 1500/2000 Cost: 1.757181\n",
      "Epoch 1600/2000 Cost: 1.661927\n",
      "Epoch 1700/2000 Cost: 1.572750\n",
      "Epoch 1800/2000 Cost: 1.489264\n",
      "Epoch 1900/2000 Cost: 1.411076\n",
      "Epoch 2000/2000 Cost: 1.337829\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "print(list(model.parameters()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Parameter containing:\n",
      "tensor([[1.0551, 0.5767, 0.3883]], requires_grad=True), Parameter containing:\n",
      "tensor([0.2791], requires_grad=True)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "import torch\r\n",
    "import torch.optim as optim\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from torch.utils.data import TensorDataset\r\n",
    "\r\n",
    "x_train = torch.FloatTensor([[73, 80, 75], [93, 88, 93], [89, 91, 80], [96, 98, 100], [73, 66, 70]])\r\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\r\n",
    "\r\n",
    "dataset = TensorDataset(x_train, y_train)\r\n",
    "dataloader = DataLoader(dataset, 2, shuffle=True)\r\n",
    "\r\n",
    "model = MultivariateLinearRegression()\r\n",
    "optimizer = optim.SGD(model.parameters(), lr = 1e-5)\r\n",
    "total_epochs = 20\r\n",
    "\r\n",
    "for epoch in range(total_epochs+1):\r\n",
    "    for batch_idx, samples in enumerate(dataloader):\r\n",
    "        #print(batch_idx)\r\n",
    "        #print(samples)\r\n",
    "        x_train, y_train = samples\r\n",
    "        prediction = model(x_train)\r\n",
    "        cost = F.mse_loss(prediction, y_train)\r\n",
    "\r\n",
    "        optimizer.zero_grad()\r\n",
    "        cost.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        print('Epoch {}/{} Batch {}/{} Cost: {:.6f}'.format(epoch, total_epochs, batch_idx+1, len(dataloader), cost.item()))\r\n",
    "        "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0/20 Batch 1/3 Cost: 39813.523438\n",
      "Epoch 0/20 Batch 2/3 Cost: 7718.927246\n",
      "Epoch 0/20 Batch 3/3 Cost: 1913.156738\n",
      "Epoch 1/20 Batch 1/3 Cost: 1263.947754\n",
      "Epoch 1/20 Batch 2/3 Cost: 423.174194\n",
      "Epoch 1/20 Batch 3/3 Cost: 171.226181\n",
      "Epoch 2/20 Batch 1/3 Cost: 47.631317\n",
      "Epoch 2/20 Batch 2/3 Cost: 11.627554\n",
      "Epoch 2/20 Batch 3/3 Cost: 0.892520\n",
      "Epoch 3/20 Batch 1/3 Cost: 4.801873\n",
      "Epoch 3/20 Batch 2/3 Cost: 3.530174\n",
      "Epoch 3/20 Batch 3/3 Cost: 4.487589\n",
      "Epoch 4/20 Batch 1/3 Cost: 1.407378\n",
      "Epoch 4/20 Batch 2/3 Cost: 4.184358\n",
      "Epoch 4/20 Batch 3/3 Cost: 2.037946\n",
      "Epoch 5/20 Batch 1/3 Cost: 1.664627\n",
      "Epoch 5/20 Batch 2/3 Cost: 3.205698\n",
      "Epoch 5/20 Batch 3/3 Cost: 2.843589\n",
      "Epoch 6/20 Batch 1/3 Cost: 1.862180\n",
      "Epoch 6/20 Batch 2/3 Cost: 1.189107\n",
      "Epoch 6/20 Batch 3/3 Cost: 7.936528\n",
      "Epoch 7/20 Batch 1/3 Cost: 1.893118\n",
      "Epoch 7/20 Batch 2/3 Cost: 5.083883\n",
      "Epoch 7/20 Batch 3/3 Cost: 1.962162\n",
      "Epoch 8/20 Batch 1/3 Cost: 5.357918\n",
      "Epoch 8/20 Batch 2/3 Cost: 2.842120\n",
      "Epoch 8/20 Batch 3/3 Cost: 1.360269\n",
      "Epoch 9/20 Batch 1/3 Cost: 2.157495\n",
      "Epoch 9/20 Batch 2/3 Cost: 3.932734\n",
      "Epoch 9/20 Batch 3/3 Cost: 1.398223\n",
      "Epoch 10/20 Batch 1/3 Cost: 5.613550\n",
      "Epoch 10/20 Batch 2/3 Cost: 2.950539\n",
      "Epoch 10/20 Batch 3/3 Cost: 0.841322\n",
      "Epoch 11/20 Batch 1/3 Cost: 0.241022\n",
      "Epoch 11/20 Batch 2/3 Cost: 7.229364\n",
      "Epoch 11/20 Batch 3/3 Cost: 2.621320\n",
      "Epoch 12/20 Batch 1/3 Cost: 0.746355\n",
      "Epoch 12/20 Batch 2/3 Cost: 6.262480\n",
      "Epoch 12/20 Batch 3/3 Cost: 2.888693\n",
      "Epoch 13/20 Batch 1/3 Cost: 1.166240\n",
      "Epoch 13/20 Batch 2/3 Cost: 2.054691\n",
      "Epoch 13/20 Batch 3/3 Cost: 6.393330\n",
      "Epoch 14/20 Batch 1/3 Cost: 1.877824\n",
      "Epoch 14/20 Batch 2/3 Cost: 2.743607\n",
      "Epoch 14/20 Batch 3/3 Cost: 6.454434\n",
      "Epoch 15/20 Batch 1/3 Cost: 3.152393\n",
      "Epoch 15/20 Batch 2/3 Cost: 1.906926\n",
      "Epoch 15/20 Batch 3/3 Cost: 2.589891\n",
      "Epoch 16/20 Batch 1/3 Cost: 1.646745\n",
      "Epoch 16/20 Batch 2/3 Cost: 1.369858\n",
      "Epoch 16/20 Batch 3/3 Cost: 7.924840\n",
      "Epoch 17/20 Batch 1/3 Cost: 1.670353\n",
      "Epoch 17/20 Batch 2/3 Cost: 3.130939\n",
      "Epoch 17/20 Batch 3/3 Cost: 2.756676\n",
      "Epoch 18/20 Batch 1/3 Cost: 4.271344\n",
      "Epoch 18/20 Batch 2/3 Cost: 3.288540\n",
      "Epoch 18/20 Batch 3/3 Cost: 1.456409\n",
      "Epoch 19/20 Batch 1/3 Cost: 0.499265\n",
      "Epoch 19/20 Batch 2/3 Cost: 4.792744\n",
      "Epoch 19/20 Batch 3/3 Cost: 2.644892\n",
      "Epoch 20/20 Batch 1/3 Cost: 3.085892\n",
      "Epoch 20/20 Batch 2/3 Cost: 2.926263\n",
      "Epoch 20/20 Batch 3/3 Cost: 2.234919\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "현재 위의 dataloader는 batch_idx와 sample로 이루어져 있음. 그리고 sample은 두개의 tensor로 x 데이터와 y 데이터로 구분되어 있음을 유의하자"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 커스텀 데이터셋으로 선형 회귀 구현하기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "import torch\r\n",
    "import torch.nn.functional as F\r\n",
    "\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from torch.utils.data import Dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "import torch\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim\r\n",
    "import torch.nn as nn\r\n",
    "\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from torch.utils.data import Dataset\r\n",
    "\r\n",
    "\r\n",
    "class CustomDataset(Dataset):\r\n",
    "    def __init__(self):\r\n",
    "        self.x_data = [[73, 80, 75], [93, 88, 93], [89, 91, 80], [96, 98, 100], [73, 66, 70]]\r\n",
    "        self.y_data = [[152], [185], [180], [196], [142]]\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.x_data)\r\n",
    "\r\n",
    "    def __getitem__(self, index):\r\n",
    "        x = torch.tensor(self.x_data[index])\r\n",
    "        y = torch.tensor(self.y_data[index])\r\n",
    "        return x,y\r\n",
    "\r\n",
    "\r\n",
    "dataset = CustomDataset()\r\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\r\n",
    "model = nn.Linear(3,1)\r\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)\r\n",
    "total_epochs = 20\r\n",
    "\r\n",
    "for epoch in range(total_epochs + 1):\r\n",
    "    for batch_idx, sample in enumerate(dataloader):\r\n",
    "        \r\n",
    "        x_train, y_train = sample\r\n",
    "        \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "len(x_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('main': conda)"
  },
  "interpreter": {
   "hash": "5777bc8a7577125a1c00ed1671130ea029cae56addc813f4c39a4f837e26f28b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}